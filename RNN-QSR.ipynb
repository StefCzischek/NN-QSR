{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45797e5b",
   "metadata": {},
   "source": [
    "# Exploring RNN architectures for Quantum state representation\n",
    "\n",
    "A couple types of rnn:\n",
    "    \n",
    "    Gru\n",
    "    \n",
    "    Lstm\n",
    "    \n",
    "    2D lstm (if we have a 2d input)\n",
    "    \n",
    "    Tranformer (masked) (masked makes it causal whereas unmasked would be non causal)\n",
    "    \n",
    "Extra networks:\n",
    "\n",
    "    Echo state networks  -> look into\n",
    "    \n",
    "    Resevoir computing cells -> look into\n",
    "        \n",
    "        Apparently you only train the output weights -> avoids a bunch of backprop\n",
    "        \n",
    "        but we use it in a recurrent fashion so you need to backprop still\n",
    "        \n",
    "        Look at BYOL for this (might not be possible)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae4fa75",
   "metadata": {},
   "source": [
    "# Quantum state to represent\n",
    "\n",
    "- Start with Rydberg system\n",
    "\n",
    "Transverse and longitudinal view of ising model\n",
    "\n",
    "Excited state encourages nearby (within radius $R_b$)states to tend towards ground states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd7f3dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math,time\n",
    "import torch\n",
    "from torch import nn\n",
    "ngpu=1\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "print(device)\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89741030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.38052\n"
     ]
    }
   ],
   "source": [
    "# Hamiltonian parameters\n",
    "Lx = 16      # Linear size in x direction\n",
    "Ly = 16      # Linear size in y direction\n",
    "N = Lx*Ly   # Total number of atoms\n",
    "V = 7.0     # Strength of Van der Waals interaction\n",
    "Omega = 1.0 # Rabi frequency\n",
    "delta = 1.0 # Detuning \n",
    "exact_energy = {16:-0.45776822,64:-0.40522,144:-0.38852,256:-0.38052}[Lx*Ly]\n",
    "print(exact_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d13afa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler(nn.Module):\n",
    "    def __init__(self,device=device):\n",
    "        self.device=device\n",
    "        super(Sampler, self).__init__()\n",
    "    def logprobability(self,input):\n",
    "        \"\"\"Compute the logscale probability of a given state\n",
    "            Inputs:\n",
    "                input - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "            Returns:\n",
    "                logp - [B] size vector of logscale probability labels\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    def sample(self,B,L):\n",
    "        \"\"\" Generates a set states\n",
    "        Inputs:\n",
    "            B (int)            - The number of states to generate in parallel\n",
    "            L (int)            - The length of generated vectors\n",
    "        Returns:\n",
    "            samples - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def sample_with_labels(self,B,L,grad=False):\n",
    "        \"\"\"Inputs:\n",
    "            B (int) - The number of states to generate in parallel\n",
    "            L (int) - The length of generated vectors\n",
    "            grad (boolean) - Whether or not to use gradients\n",
    "        Returns:\n",
    "            samples - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "            logppl - [B,L] matrix of logscale probabilities ln[p(s')] where s'[i+B*j] had one spin flipped at position j\n",
    "                    relative to s[i]\n",
    "        \"\"\"\n",
    "        sample=self.sample(B,L)\n",
    "        sflip = torch.zeros([B,L,L,1],device=self.device)\n",
    "        for j in range(L):\n",
    "            #get all of the states with one spin flipped\n",
    "            sflip[:,j] = sample*1.0\n",
    "            sflip[:,j,j] = 1-sflip[:,j,j]\n",
    "        #compute all of their logscale probabilities\n",
    "        if not grad:\n",
    "            with torch.no_grad():\n",
    "                probs = self.logprobability(sflip.view([B*L,L,1]))\n",
    "        else:\n",
    "            probs = self.logprobability(sflip.view([B*L,L,1]))\n",
    "            \n",
    "        #might make sflip shape [B,L] in the future\n",
    "        return sample,probs.reshape([B,L])\n",
    "    \n",
    "    def sample_with_labelsALT(self,B,L,grad=False):\n",
    "        \"\"\"Returns:\n",
    "            samples  - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "            logsqrtp - size B vector of average (log p)/2 values used for numerical stability \n",
    "                       when calculating sum_s'(sqrt[p(s')/p(s)]) \n",
    "            sumsqrtp - size B vector of exp(-logsqrtp)*sum(sqrt[p(s')]).\n",
    "        \"\"\"\n",
    "        sample,probs = self.sample_with_labels(B,L,grad)\n",
    "        #get the average of our logprobabilities and divide by 2\n",
    "        logsqrtp=probs.mean(dim=1)/2\n",
    "        #compute the sum with a constant multiplied to keep the sum closeish to 1\n",
    "        sumsqrtp = torch.exp(probs/2-logsqrtp.unsqueeze(1)).sum(dim=1)\n",
    "        return sample,sumsqrtp,logsqrtp\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab5dec33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Sampler in module __main__:\n",
      "\n",
      "class Sampler(torch.nn.modules.module.Module)\n",
      " |  Sampler(device=device(type='cuda', index=0))\n",
      " |  \n",
      " |  Base class for all neural network modules.\n",
      " |  \n",
      " |  Your models should also subclass this class.\n",
      " |  \n",
      " |  Modules can also contain other Modules, allowing to nest them in\n",
      " |  a tree structure. You can assign the submodules as regular attributes::\n",
      " |  \n",
      " |      import torch.nn as nn\n",
      " |      import torch.nn.functional as F\n",
      " |  \n",
      " |      class Model(nn.Module):\n",
      " |          def __init__(self):\n",
      " |              super(Model, self).__init__()\n",
      " |              self.conv1 = nn.Conv2d(1, 20, 5)\n",
      " |              self.conv2 = nn.Conv2d(20, 20, 5)\n",
      " |  \n",
      " |          def forward(self, x):\n",
      " |              x = F.relu(self.conv1(x))\n",
      " |              return F.relu(self.conv2(x))\n",
      " |  \n",
      " |  Submodules assigned in this way will be registered, and will have their\n",
      " |  parameters converted too when you call :meth:`to`, etc.\n",
      " |  \n",
      " |  :ivar training: Boolean represents whether this module is in training or\n",
      " |                  evaluation mode.\n",
      " |  :vartype training: bool\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Sampler\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, device=device(type='cuda', index=0))\n",
      " |      Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
      " |  \n",
      " |  logprobability(self, input)\n",
      " |      Compute the logscale probability of a given state\n",
      " |      Inputs:\n",
      " |          input - [B,L,1] matrix of zeros and ones for ground/excited states\n",
      " |      Returns:\n",
      " |          logp - [B] size vector of logscale probability labels\n",
      " |  \n",
      " |  sample(self, B, L)\n",
      " |      Generates a set states\n",
      " |      Inputs:\n",
      " |          B (int)            - The number of states to generate in parallel\n",
      " |          L (int)            - The length of generated vectors\n",
      " |      Returns:\n",
      " |          samples - [B,L,1] matrix of zeros and ones for ground/excited states\n",
      " |  \n",
      " |  sample_with_labels(self, B, L, grad=False)\n",
      " |      Inputs:\n",
      " |          B (int) - The number of states to generate in parallel\n",
      " |          L (int) - The length of generated vectors\n",
      " |          grad (boolean) - Whether or not to use gradients\n",
      " |      Returns:\n",
      " |          samples - [B,L,1] matrix of zeros and ones for ground/excited states\n",
      " |          logppl - [B,L] matrix of logscale probabilities ln[p(s')] where s'[i+B*j] had one spin flipped at position j\n",
      " |                  relative to s[i]\n",
      " |  \n",
      " |  sample_with_labelsALT(self, B, L, grad=False)\n",
      " |      Returns:\n",
      " |      samples  - [B,L,1] matrix of zeros and ones for ground/excited states\n",
      " |      logsqrtp - size B vector of average (log p)/2 values used for numerical stability \n",
      " |                 when calculating sum_s'(sqrt[p(s')/p(s)]) \n",
      " |      sumsqrtp - size B vector of exp(-logsqrtp)*sum(sqrt[p(s')]).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__ = _call_impl(self, *input, **kwargs)\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Default dir() implementation.\n",
      " |  \n",
      " |  __getattr__(self, name: str) -> Union[torch.Tensor, ForwardRef('Module')]\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name: str, value: Union[torch.Tensor, ForwardRef('Module')]) -> None\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_module(self, name: str, module: Union[ForwardRef('Module'), NoneType]) -> None\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          module (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self: ~T, fn: Callable[[ForwardRef('Module')], NoneType]) -> ~T\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`nn-init-doc`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> @torch.no_grad()\n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  bfloat16(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  buffers(self, recurse: bool = True) -> Iterator[torch.Tensor]\n",
      " |      Returns an iterator over module buffers.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf), buf.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  children(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  cpu(self: ~T) -> ~T\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self: ~T) -> ~T\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.eval()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  extra_repr(self) -> str\n",
      " |      Set the extra representation of the module\n",
      " |      \n",
      " |      To print customized extra information, you should re-implement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  float(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``float`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  forward = _forward_unimplemented(self, *input: Any) -> None\n",
      " |      Defines the computation performed at every call.\n",
      " |      \n",
      " |      Should be overridden by all subclasses.\n",
      " |      \n",
      " |      .. note::\n",
      " |          Although the recipe for forward pass needs to be defined within\n",
      " |          this function, one should call the :class:`Module` instance afterwards\n",
      " |          instead of this since the former takes care of running the\n",
      " |          registered hooks while the latter silently ignores them.\n",
      " |  \n",
      " |  get_buffer(self, target: str) -> 'Tensor'\n",
      " |      Returns the buffer given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the buffer\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.Tensor: The buffer referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not a\n",
      " |              buffer\n",
      " |  \n",
      " |  get_parameter(self, target: str) -> 'Parameter'\n",
      " |      Returns the parameter given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the Parameter\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Parameter: The Parameter referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Parameter``\n",
      " |  \n",
      " |  get_submodule(self, target: str) -> 'Module'\n",
      " |      Returns the submodule given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      For example, let's say you have an ``nn.Module`` ``A`` that\n",
      " |      looks like this:\n",
      " |      \n",
      " |      .. code-block::text\n",
      " |      \n",
      " |          A(\n",
      " |              (net_b): Module(\n",
      " |                  (net_c): Module(\n",
      " |                      (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\n",
      " |                  )\n",
      " |                  (linear): Linear(in_features=100, out_features=200, bias=True)\n",
      " |              )\n",
      " |          )\n",
      " |      \n",
      " |      (The diagram shows an ``nn.Module`` ``A``. ``A`` has a nested\n",
      " |      submodule ``net_b``, which itself has two submodules ``net_c``\n",
      " |      and ``linear``. ``net_c`` then has a submodule ``conv``.)\n",
      " |      \n",
      " |      To check whether or not we have the ``linear`` submodule, we\n",
      " |      would call ``get_submodule(\"net_b.linear\")``. To check whether\n",
      " |      we have the ``conv`` submodule, we would call\n",
      " |      ``get_submodule(\"net_b.net_c.conv\")``.\n",
      " |      \n",
      " |      The runtime of ``get_submodule`` is bounded by the degree\n",
      " |      of module nesting in ``target``. A query against\n",
      " |      ``named_modules`` achieves the same result, but it is O(N) in\n",
      " |      the number of transitive modules. So, for a simple check to see\n",
      " |      if some submodule exists, ``get_submodule`` should always be\n",
      " |      used.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the submodule\n",
      " |              to look for. (See above example for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Module: The submodule referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Module``\n",
      " |  \n",
      " |  half(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict: 'OrderedDict[str, Tensor]', strict: bool = True)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      Args:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |      \n",
      " |      Returns:\n",
      " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      " |              * **missing_keys** is a list of str containing the missing keys\n",
      " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
      " |  \n",
      " |  modules(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      " |  \n",
      " |  named_buffers(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n",
      " |      Returns an iterator over module buffers, yielding both the\n",
      " |      name of the buffer as well as the buffer itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, torch.Tensor): Tuple containing the name and buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>    if name in ['running_var']:\n",
      " |          >>>        print(buf.size())\n",
      " |  \n",
      " |  named_children(self) -> Iterator[Tuple[str, ForwardRef('Module')]]\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo: Union[Set[ForwardRef('Module')], NoneType] = None, prefix: str = '', remove_duplicate: bool = True)\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          memo: a memo to store the set of modules already added to the result\n",
      " |          prefix: a prefix that will be added to the name of the module\n",
      " |          remove_duplicate: whether to remove the duplicated module instances in the result\n",
      " |          or not\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      " |  \n",
      " |  named_parameters(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.nn.parameter.Parameter]]\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>    if name in ['bias']:\n",
      " |          >>>        print(param.size())\n",
      " |  \n",
      " |  parameters(self, recurse: bool = True) -> Iterator[torch.nn.parameter.Parameter]\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param), param.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      This function is deprecated in favor of :meth:`nn.Module.register_full_backward_hook` and\n",
      " |      the behavior of this function will change in future versions.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_buffer(self, name: str, tensor: Union[torch.Tensor, NoneType], persistent: bool = True) -> None\n",
      " |      Adds a buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the module's state. Buffers, by\n",
      " |      default, are persistent and will be saved alongside parameters. This\n",
      " |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n",
      " |      only difference between a persistent buffer and a non-persistent buffer\n",
      " |      is that the latter will not be a part of this module's\n",
      " |      :attr:`state_dict`.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor): buffer to be registered.\n",
      " |          persistent (bool): whether the buffer is part of this module's\n",
      " |              :attr:`state_dict`.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input, output) -> None or modified output\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the output. It can modify the input inplace but\n",
      " |      it will not have effect on forward since this is called after\n",
      " |      :func:`forward` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input) -> None or modified input\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the input. User can either return a tuple or a\n",
      " |      single modified value in the hook. We will wrap the value into a tuple\n",
      " |      if a single value is returned(unless that value is already a tuple).\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_full_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to module\n",
      " |      inputs are computed. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> tuple(Tensor) or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` are tuples that contain the gradients\n",
      " |      with respect to the inputs and outputs respectively. The hook should\n",
      " |      not modify its arguments, but it can optionally return a new gradient with\n",
      " |      respect to the input that will be used in place of :attr:`grad_input` in\n",
      " |      subsequent computations. :attr:`grad_input` will only correspond to the inputs given\n",
      " |      as positional arguments and all kwarg arguments are ignored. Entries\n",
      " |      in :attr:`grad_input` and :attr:`grad_output` will be ``None`` for all non-Tensor\n",
      " |      arguments.\n",
      " |      \n",
      " |      .. warning ::\n",
      " |          Modifying inputs or outputs inplace is not allowed when using backward hooks and\n",
      " |          will raise an error.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_parameter(self, name: str, param: Union[torch.nn.parameter.Parameter, NoneType]) -> None\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          param (Parameter): parameter to be added to the module.\n",
      " |  \n",
      " |  requires_grad_(self: ~T, requires_grad: bool = True) -> ~T\n",
      " |      Change if autograd should record operations on parameters in this\n",
      " |      module.\n",
      " |      \n",
      " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
      " |      in-place.\n",
      " |      \n",
      " |      This method is helpful for freezing part of the module for finetuning\n",
      " |      or training parts of a model individually (e.g., GAN training).\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.requires_grad_()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Args:\n",
      " |          requires_grad (bool): whether autograd should record operations on\n",
      " |                                parameters in this module. Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  share_memory(self: ~T) -> ~T\n",
      " |      See :meth:`torch.Tensor.share_memory_`\n",
      " |  \n",
      " |  state_dict(self, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing a whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Moves and/or casts the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(memory_format=torch.channels_last)\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point or complex :attr:`dtype`s. In addition, this method will\n",
      " |      only cast the floating point or complex parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point or complex dtype of\n",
      " |              the parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |          memory_format (:class:`torch.memory_format`): the desired memory\n",
      " |              format for 4D parameters and buffers in this module (keyword\n",
      " |              only argument)\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.3741+0.j,  0.2382+0.j],\n",
      " |                  [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)\n",
      " |          >>> linear(torch.ones(3, 2, dtype=torch.cdouble))\n",
      " |          tensor([[0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)\n",
      " |  \n",
      " |  to_empty(self: ~T, *, device: Union[str, torch.device]) -> ~T\n",
      " |      Moves the parameters and buffers to the specified device without copying storage.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): The desired device of the parameters\n",
      " |              and buffers in this module.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  train(self: ~T, mode: bool = True) -> ~T\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
      " |                       mode (``False``). Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self: ~T, dst_type: Union[torch.dtype, str]) -> ~T\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  xpu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the XPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on XPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self, set_to_none: bool = False) -> None\n",
      " |      Sets gradients of all model parameters to zero. See similar function\n",
      " |      under :class:`torch.optim.Optimizer` for more context.\n",
      " |      \n",
      " |      Args:\n",
      " |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
      " |              See :meth:`torch.optim.Optimizer.zero_grad` for details.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  T_destination = ~T_destination\n",
      " |  \n",
      " |  __annotations__ = {'__call__': typing.Callable[..., typing.Any], '_is_...\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb026d6",
   "metadata": {},
   "source": [
    "# Simple RNN to start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e73a0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(Sampler):\n",
    "    TYPES={\"GRU\":nn.GRU,\"ELMAN\":nn.RNN,\"LSTM\":nn.LSTM}\n",
    "    def __init__(self,rnntype=\"GRU\",Nh=128,device=device, **kwargs):\n",
    "        super(RNN, self).__init__(device=device)\n",
    "        #rnn takes input shape [B,L,1]\n",
    "        self.rnn = RNN.TYPES[rnntype](input_size=1,hidden_size=Nh,batch_first=True)\n",
    "        \n",
    "        \n",
    "        self.lin = nn.Sequential(\n",
    "                nn.Linear(128,128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128,1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "        self.rnntype=rnntype\n",
    "        self.to(device)\n",
    "    def forward(self, input):\n",
    "        # h0 is shape [d*numlayers,B,H] but D=numlayers=1 so\n",
    "        # h0 has shape [1,B,H]\n",
    "        \n",
    "        if self.rnntype==\"LSTM\":\n",
    "            h0=[torch.zeros([1,input.shape[0],128],device=self.device),\n",
    "               torch.zeros([1,input.shape[0],128],device=self.device)]\n",
    "            #h0 and c0\n",
    "        else:\n",
    "            h0=torch.zeros([1,input.shape[0],128],device=self.device)\n",
    "        out,h=self.rnn(input,h0)\n",
    "        return self.lin(out)\n",
    "    \n",
    "    def logprobability(self,input):\n",
    "        \"\"\"Compute the logscale probability of a given state\n",
    "            Inputs:\n",
    "                input - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "            Returns:\n",
    "                logp - [B] size vector of logscale probability labels\n",
    "        \"\"\"\n",
    "        \n",
    "        #Input should have shape [B,L,1]\n",
    "        B,L,one=input.shape\n",
    "        \n",
    "        #first prediction is with the zero input vector\n",
    "        data=torch.zeros([B,L,one],device=self.device)\n",
    "        #data is the input vector shifted one to the right, with the very first entry set to zero instead of using pbc\n",
    "        data[:,1:,:]=input[:,:-1,:]\n",
    "        \n",
    "        #real is going to be a set of actual values\n",
    "        real=input\n",
    "        #and pred is going to be a set of probabilities\n",
    "        #if real[i]=1 than you muptiply your conditional probability by pred[i]\n",
    "        #if real[i]=0 than you muliply by 1-pred[i]\n",
    "        \n",
    "        #probability predictions should be done WITH gradients\n",
    "        #with torch.no_grad():\n",
    "        \n",
    "        pred = self.forward(data)\n",
    "        ones = real*pred\n",
    "        zeros=(1-real)*(1-pred)\n",
    "        total = ones+zeros\n",
    "        #this is the sum you see in the cell above\n",
    "        #add 1e-10 to the prediction to avoid nans when total=0\n",
    "        logp=torch.sum(torch.log(total+1e-10),dim=1).squeeze(1)\n",
    "        return logp\n",
    "    def sample(self,B,L):\n",
    "        \"\"\" Generates a set states\n",
    "        Inputs:\n",
    "            B (int)            - The number of states to generate in parallel\n",
    "            L (int)            - The length of generated vectors\n",
    "        Returns:\n",
    "            samples - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "        \"\"\"\n",
    "        if self.rnntype==\"LSTM\":\n",
    "            h=[torch.zeros([1,B,128],device=self.device),\n",
    "               torch.zeros([1,B,128],device=self.device)]\n",
    "            #h is h0 and c0\n",
    "        else:\n",
    "            h=torch.zeros([1,B,128],device=self.device)\n",
    "        #Sample set will have shape [N,L,1]\n",
    "        #need one extra zero batch at the start for first pred hence input is [N,L+1,1] \n",
    "        input = torch.zeros([B,L+1,1],device=self.device)\n",
    "        #sampling can be done without gradients\n",
    "        with torch.no_grad():\n",
    "          for idx in range(1,L+1):\n",
    "            #run the rnn on shape [B,1,1]\n",
    "            \n",
    "            out,h=self.rnn(input[:,idx-1:idx,:],h)\n",
    "            out=out[:,0,:]\n",
    "            #if probs[i]=1 then there should be a 100% chance that sample[i]=1\n",
    "            #if probs[i]=0 then there should be a 0% chance that sample[i]=1\n",
    "            #stands that we generate a random uniform u and take int(u<probs) as our sample\n",
    "            probs=self.lin(out)\n",
    "            sample = (torch.rand([B,1],device=device)<probs).to(torch.float32)\n",
    "            input[:,idx,:]=sample\n",
    "        #input's first entry is zero to get a predction for the first atom\n",
    "        return input[:,1:,:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49e73636",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def Vij(Ly,Lx,Rcutoff,V,matrix):\n",
    "    #matrix will be size [Lx*Ly,Lx*Ly]\n",
    "    \n",
    "    i,j=cuda.grid(2)\n",
    "    if i>Ly or j>Lx:\n",
    "        return\n",
    "    R=Rcutoff**6\n",
    "    #flatten two indices into one\n",
    "    idx = Ly*j+i\n",
    "    # only fill in the upper diagonal\n",
    "    for k in range(idx+1,Lx*Ly):\n",
    "        #expand one index into two\n",
    "        i2 = k%Ly\n",
    "        j2=k//Ly\n",
    "        div = ((i2-i)**2+(j2-j)**2)**3\n",
    "        if div<=R:\n",
    "            matrix[idx][k]=V/div\n",
    "    \n",
    "\n",
    "class Hamiltonian():\n",
    "    def __init__(self,Lx,Ly,V,Omega,delta,R=2.01,device=device):\n",
    "        self.Lx       = Lx              # Size along x\n",
    "        self.Ly       = Ly              # Size along y\n",
    "        self.V        = V               # Van der Waals potential\n",
    "        self.Omega    = Omega           # Rabi frequency\n",
    "        self.delta    = delta           # Detuning\n",
    "        self.L        = Lx * Ly         # Number of spins\n",
    "        self.device   = device\n",
    "        self.R=R\n",
    "        self.buildlattice()\n",
    "        \n",
    "    def buildlattice(self):\n",
    "        Lx,Ly=self.Lx,self.Ly\n",
    "        \n",
    "        #diagonal hamiltonian portion can be written as a matrix multiplication then a dot product\n",
    "        self.Vij=nn.Linear(self.L,self.L).to(device)\n",
    "        \n",
    "        mat=np.zeros([self.L,self.L])\n",
    "        \n",
    "        Vij[(1,1),(Lx,Ly)](Lx,Ly,self.R,self.V,mat)\n",
    "        with torch.no_grad():\n",
    "            self.Vij.weight[:,:]=torch.Tensor(mat)\n",
    "            self.Vij.bias.fill_(-self.delta)\n",
    "\n",
    "\n",
    "    def localenergy(self,samples,logp,logppj):\n",
    "        \"\"\"\n",
    "        Takes in s, ln[p(s)] and ln[p(s')] (for all s'), then computes Hloc(s) for N samples s.\n",
    "        \n",
    "        Inputs:\n",
    "            samples - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "            logp - size B vector of logscale probabilities ln[p(s)]\n",
    "            logppj - [B,L] matrix of logscale probabilities ln[p(s')] where s'[i][j] had one spin flipped at position j\n",
    "                    relative to s[i]\n",
    "        Returns:\n",
    "            size B vector of energies Hloc(s)\n",
    "        \n",
    "        \"\"\"\n",
    "        # Going to calculate Eloc for each sample in a separate spot\n",
    "        # so eloc will have shape [B]\n",
    "        # recall samples has shape [B,L,1]\n",
    "        B=samples.shape[0]\n",
    "        eloc = torch.zeros(B,device=self.device)\n",
    "        # Chemical potential\n",
    "        with torch.no_grad():\n",
    "            tmp=self.Vij(samples.squeeze(2))\n",
    "            eloc += torch.sum(tmp*samples.squeeze(2),axis=1)\n",
    "        # Off-diagonal part\n",
    "        #flip ONE spin here and get sqrt(p(s)/p(s'))\n",
    "        #then sum over all spin flips\n",
    "        #think of ways to cheat\n",
    "        \n",
    "        #logppj is shape [B*L]\n",
    "        # the first N labels in logppj are the log probabilities for\n",
    "        # the N states but with the first state flipped (ground-> excited and excited-> ground)\n",
    "        # the second N all were calculated with only the second state flipped \n",
    "        # etc...\n",
    "        for j in range(self.L):\n",
    "            #logpflip is log(p(1-s))\n",
    "            #logp is log(p(s))?\n",
    "            #s' has one spin flipped at j\n",
    "            #with psi(s)=sqrt(p(s)), sigma_i^x = psi(s')/psi(s)?\n",
    "            \n",
    "            #make sure torch.exp is a thing\n",
    "            eloc += -0.5*self.Omega * torch.exp((logppj[:,j]-logp)/2)\n",
    "\n",
    "        return eloc\n",
    "    def localenergyALT(self,samples,logp,sumsqrtp,logsqrtp):\n",
    "        \"\"\"\n",
    "        Takes in s, ln[p(s)] and exp(-logsqrtp)*sum(sqrt[p(s')]), then computes Hloc(s) for N samples s.\n",
    "        \n",
    "        Inputs:\n",
    "            samples  - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "            logp     - size B vector of logscale probabilities ln[p(s)]\n",
    "            logsqrtp - size B vector of average (log p)/2 values used for numerical stability \n",
    "                       when calculating sum_s'(sqrt[p(s')/p(s)]) \n",
    "            sumsqrtp - size B vector of exp(-logsqrtp)*sum(sqrt[p(s')]).\n",
    "        Returns:\n",
    "            size B vector of energies Hloc(s)\n",
    "        \n",
    "        \"\"\"\n",
    "        # Going to calculate Eloc for each sample in a separate spot\n",
    "        # so eloc will have shape [B]\n",
    "        # recall samples has shape [B,L,1]\n",
    "        B=samples.shape[0]\n",
    "        eloc = torch.zeros(B,device=self.device)\n",
    "        # Chemical potential\n",
    "        with torch.no_grad():\n",
    "            tmp=self.Vij(samples.squeeze(2))\n",
    "            eloc += torch.sum(tmp*samples.squeeze(2),axis=1)\n",
    "        # Off-diagonal part\n",
    "        #flip ONE spin here and get sqrt(p(s)/p(s'))\n",
    "        #then sum over all spin flips\n",
    "        #think of ways to cheat\n",
    "        \n",
    "        eloc += -0.5*self.Omega *sumsqrtp* torch.exp(logsqrtp-logp/2)\n",
    "\n",
    "        return eloc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00252ab1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Hamiltonian in module __main__:\n",
      "\n",
      "class Hamiltonian(builtins.object)\n",
      " |  Hamiltonian(Lx, Ly, V, Omega, delta, R=2.01, device=device(type='cuda', index=0))\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, Lx, Ly, V, Omega, delta, R=2.01, device=device(type='cuda', index=0))\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  buildlattice(self)\n",
      " |  \n",
      " |  localenergy(self, samples, logp, logppj)\n",
      " |      Takes in s, ln[p(s)] and ln[p(s')] (for all s'), then computes Hloc(s) for N samples s.\n",
      " |      \n",
      " |      Inputs:\n",
      " |          samples - [B,L,1] matrix of zeros and ones for ground/excited states\n",
      " |          logp - size B vector of logscale probabilities ln[p(s)]\n",
      " |          logppj - [B,L] matrix of logscale probabilities ln[p(s')] where s'[i][j] had one spin flipped at position j\n",
      " |                  relative to s[i]\n",
      " |      Returns:\n",
      " |          size B vector of energies Hloc(s)\n",
      " |  \n",
      " |  localenergyALT(self, samples, logp, sumsqrtp, logsqrtp)\n",
      " |      Takes in s, ln[p(s)] and exp(-logsqrtp)*sum(sqrt[p(s')]), then computes Hloc(s) for N samples s.\n",
      " |      \n",
      " |      Inputs:\n",
      " |          samples  - [B,L,1] matrix of zeros and ones for ground/excited states\n",
      " |          logp     - size B vector of logscale probabilities ln[p(s)]\n",
      " |          logsqrtp - size B vector of average (log p)/2 values used for numerical stability \n",
      " |                     when calculating sum_s'(sqrt[p(s')/p(s)]) \n",
      " |          sumsqrtp - size B vector of exp(-logsqrtp)*sum(sqrt[p(s')]).\n",
      " |      Returns:\n",
      " |          size B vector of energies Hloc(s)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Hamiltonian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39b5e139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM\n",
      "torch.Size([10, 16, 1])\n",
      "torch.Size([10, 16, 1])\n",
      "torch.Size([10, 16, 1]) torch.Size([10, 16])\n",
      "tensor(-11.0885, device='cuda:0', grad_fn=<SelectBackward>) \n",
      " tensor([[-11.0639, -11.0646, -11.1141, -11.1137, -11.1137, -11.0658, -11.1144,\n",
      "         -11.0643, -11.0640, -11.1143, -11.0644, -11.0652, -11.1136, -11.1136,\n",
      "         -11.1134, -11.0661]], device='cuda:0')\n",
      "RNN(\n",
      "  (rnn): LSTM(1, 128, batch_first=True)\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "testrnn = RNN(rnntype=\"LSTM\")\n",
    "print(testrnn.rnntype)\n",
    "x=torch.zeros([10,4*4,1]).to(device)\n",
    "print(testrnn(x).shape)\n",
    "sample = testrnn.sample(10,4*4)\n",
    "print(sample.shape)\n",
    "\n",
    "sample,pflip = testrnn.sample_with_labels(10,4*4,grad=False)\n",
    "logp=testrnn.logprobability(sample)\n",
    "print(sample.shape,pflip.shape)\n",
    "print(logp[0],'\\n',pflip[::10])\n",
    "\n",
    "print(testrnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d5e48cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_rnn_with_optim(rnntype,Nh,lr=1e-3,beta1=0.9,beta2=0.999):\n",
    "    rnn = RNN(rnntype=rnntype,Nh=Nh)\n",
    "    optimizer = torch.optim.Adam(\n",
    "    rnn.parameters(), \n",
    "    lr=lr, \n",
    "    betas=(beta1,beta2)\n",
    "    )\n",
    "    return rnn,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "525888b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = Hamiltonian(Lx,Ly,V,Omega,delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3205a80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4888, 0.4875, 0.4868, 0.4865], device='cuda:0')\n",
      "tensor([0.5226, 0.5246, 0.5256, 0.5261], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "bsize=512\n",
    "\n",
    "testrnn,optimizer=new_rnn_with_optim(\"GRU\",128,lr=1e-3)\n",
    "samplernn = RNN(rnntype=\"GRU\",Nh=128)\n",
    "with torch.no_grad():\n",
    "    print(testrnn(torch.zeros([1,4,1],device=device))[0,:,0])\n",
    "    print(samplernn(torch.zeros([1,4,1],device=device))[0,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07dbc8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum_update(m, target_network, network):\n",
    "    for target_param, param in zip(target_network.parameters(), network.parameters()):\n",
    "        target_param.data.copy_(target_param.data*m + param.data*(1-m))\n",
    "with torch.no_grad():\n",
    "    momentum_update(0.0,samplernn,testrnn)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04437d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4888, 0.4875, 0.4868, 0.4865], device='cuda:0')\n",
      "tensor([0.4888, 0.4875, 0.4868, 0.4865], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(testrnn(torch.zeros([1,4,1],device=device))[0,:,0])\n",
    "    print(samplernn(torch.zeros([1,4,1],device=device))[0,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b855d365",
   "metadata": {},
   "source": [
    "# Training with Memory Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c37ca035",
   "metadata": {},
   "outputs": [],
   "source": [
    "USEQUEUE=True\n",
    "losses=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ada68df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "0,2.50|69,-0.24|138,-0.29|206,-0.31|275,-0.31|344,-0.33|413,-0.33|482,-0.34|ssssssssssssssssssssss551,-0.33|619,-0.35|688,-0.35|sssss757,-0.36|825,-0.36|894,-0.37|ssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss961,-0.34|1029,-0.37|1098,-0.37|1166,-0.37|1235,-0.37|1303,-0.38|sssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss1439,-0.37|1507,-0.38|1576,-0.38|1644.6915180683136\n"
     ]
    }
   ],
   "source": [
    "M=0.9\n",
    "BlockNum=(Lx*Ly)//8\n",
    "BbyL=bsize//BlockNum\n",
    "\n",
    "print(BbyL*BlockNum)\n",
    "samplequeue = torch.zeros([bsize,Lx*Ly,1]).to(device)\n",
    "sump_queue=torch.zeros([bsize]).to(device)\n",
    "sqrtp_queue=torch.zeros([bsize]).to(device)\n",
    "Eo_queue = torch.zeros([BlockNum]).to(device)\n",
    "\n",
    "\n",
    "for i in range(BlockNum):\n",
    "    sample,sump,sqrtp = samplernn.sample_with_labelsALT(BbyL,Lx*Ly,grad=False)\n",
    "    with torch.no_grad():\n",
    "        samplequeue[i*BbyL:(i+1)*BbyL]=sample\n",
    "        sump_queue[i*BbyL:(i+1)*BbyL]=sump\n",
    "        sqrtp_queue[i*BbyL:(i+1)*BbyL]=sqrtp\n",
    "\n",
    "if not USEQUEUE:\n",
    "    nqueue_updates = BlockNum\n",
    "else:\n",
    "    nqueue_updates=1\n",
    "\n",
    "\n",
    "i=0\n",
    "t=time.time()\n",
    "for x in range(12000):\n",
    "    \n",
    "    for k in range(nqueue_updates):\n",
    "        sample,sump,sqrtp = samplernn.sample_with_labelsALT(BbyL,Lx*Ly,grad=False)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            #create and store true values for energy\n",
    "            lp=samplernn.logprobability(sample)\n",
    "            E_i=h.localenergyALT(sample,lp,sump,sqrtp)\n",
    "            Eo_queue[i]=E_i.mean()/(Lx*Ly)\n",
    "            samplequeue[i*BbyL:(i+1)*BbyL]=sample\n",
    "            sump_queue[i*BbyL:(i+1)*BbyL]=sump\n",
    "            sqrtp_queue[i*BbyL:(i+1)*BbyL]=sqrtp\n",
    "        i=(i+1)%BlockNum\n",
    "    \n",
    "    logp=testrnn.logprobability(samplequeue)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        E=h.localenergyALT(samplequeue,logp,sump_queue,sqrtp_queue)\n",
    "        Eo=E.mean()\n",
    "            \n",
    "    loss = (E*logp - Eo*logp).mean()\n",
    "    \n",
    "    ERR  = Eo/(Lx*Ly)\n",
    "    losses.append(ERR.cpu().item())\n",
    "    \n",
    "    testrnn.zero_grad()\n",
    "    #if Energy sees an unrealistic improvement\n",
    "    #ignore this at early stages\n",
    "    if x>500 and Eo_queue.min()-losses[-1]>0.2:\n",
    "        print(\"s\",end=\"\")\n",
    "        #update momentum and comtinue\n",
    "        with torch.no_grad():\n",
    "            momentum_update(M,samplernn,testrnn)\n",
    "        continue\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        momentum_update(M,samplernn,testrnn)\n",
    "    \n",
    "    \n",
    "    if x%500==0:\n",
    "        print(int(time.time()-t),end=\",%.2f|\"%(losses[-1]))\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0707871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig = plt.figure(1,figsize=(6,2.5), dpi=120, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(losses,marker='o',markersize=2,linewidth=0.0,markevery=5,label=\"RNN\")\n",
    "plt.plot([0,len(losses)],[exact_energy,exact_energy],'k--')\n",
    "\n",
    "plt.xlabel(\"Step\",fontsize=15)\n",
    "plt.ylabel(\"$\\\\langle H \\\\rangle$\",fontsize=20)\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(1,figsize=(6,2.5), dpi=120, facecolor='w', edgecolor='k')\n",
    "plt.plot(abs(np.array(losses)-exact_energy),marker='o',markersize=2,linewidth=0.0,markevery=5,label=\"RNN\")\n",
    "plt.yscale(\"log\")\n",
    "plt.ylim(5e-3,5)\n",
    "plt.xlabel(\"Step\",fontsize=15)\n",
    "plt.ylabel(\"$\\\\langle H \\\\rangle-H_{min}$\",fontsize=20)\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "928251e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003295226831436182 -0.37722477316856384\n"
     ]
    }
   ],
   "source": [
    "print(losses[-1]-exact_energy,losses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94002380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3781787157058716\n"
     ]
    }
   ],
   "source": [
    "for k in range(BlockNum):\n",
    "    sample,sump,sqrtp = testrnn.sample_with_labelsALT(BbyL,Lx*Ly,grad=False)\n",
    "    with torch.no_grad():\n",
    "        samplequeue[i*BbyL:(i+1)*BbyL]=sample\n",
    "        sump_queue[i*BbyL:(i+1)*BbyL]=sump\n",
    "        sqrtp_queue[i*BbyL:(i+1)*BbyL]=sqrtp\n",
    "    i=(i+1)%BlockNum\n",
    "logp=testrnn.logprobability(samplequeue)\n",
    "with torch.no_grad():\n",
    "    E=h.localenergyALT(samplequeue,logp,sump_queue,sqrtp_queue)\n",
    "    Eo=E.mean()\n",
    "\n",
    "ERR  = Eo/(Lx*Ly)\n",
    "\n",
    "print(ERR.detach().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "267b1b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "os.system(\"git commit -a -m \\\"Auto Commit\\\"\")\n",
    "os.system(\"git push origin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3668bf80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4003f428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.zeros(10)\n",
    "x.min().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffd1b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
