{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a30b9c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from RNN_QSR import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02694a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PE2D(nn.Module):\n",
    "    def __init__(self, d_model, Lx,Ly,device,n_encode=None):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # create constant 'pe' matrix with values dependant on \n",
    "        # pos and i\n",
    "        pe = torch.zeros(Lx*Ly, d_model)\n",
    "        \n",
    "        if type(n_encode)==type(None):\n",
    "            n_encode=3*d_model//4\n",
    "        for pos in range(Lx*Ly):\n",
    "            x=pos//Ly\n",
    "            y=pos%Ly\n",
    "            # Only going to fill 3/4 of the matrix so the\n",
    "            # occupation values are preserved\n",
    "            for i in range(0, n_encode, 4):\n",
    "                \n",
    "                #x direction encoding\n",
    "                pe[pos, i] = \\\n",
    "                math.sin(x / (10000 ** ((2 * i)/n_encode)))\n",
    "                pe[pos, i + 1] = \\\n",
    "                math.cos(x / (10000 ** ((2 * (i + 1))/n_encode)))\n",
    "                #y direction encoding\n",
    "                pe[pos, i+2] = \\\n",
    "                math.sin(y / (10000 ** ((2 * i)/n_encode)))\n",
    "                pe[pos, i + 3] = \\\n",
    "                math.cos(y / (10000 ** ((2 * (i + 1))/n_encode)))\n",
    "                \n",
    "        self.pe = pe.unsqueeze(0).to(device)\n",
    "        self.L=Lx*Ly\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:,:self.L,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "406b661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlowTransformer(Sampler):\n",
    "    def __init__(self,Lx,Ly,device=device,Nh=128,decoder=False,dropout=0.0,num_layers=3, **kwargs):\n",
    "        super(SlowTransformer, self).__init__(device=device)\n",
    "        \n",
    "        self.pe = PE2D(Nh, Lx,Ly,device)\n",
    "        \n",
    "        if decoder:\n",
    "            #Decoder only transformer\n",
    "            self.decoder_layer = nn.TransformerDecoderLayer(d_model=Nh, nhead=8, dropout=dropout)\n",
    "            self.transformer = nn.TransformerDecoder(self.decoder_layer, num_layers=num_layers)\n",
    "        else:\n",
    "            #Encoder only transformer\n",
    "            #misinterperetation on encoder made it so this code does not work\n",
    "            self.encoder_layer = nn.TransformerEncoderLayer(d_model=Nh, nhead=8, dropout=dropout)\n",
    "            self.transformer = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)        \n",
    "        \n",
    "        self.lin = nn.Sequential(\n",
    "                nn.Linear(Nh,Nh),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(Nh,1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "        \n",
    "        self.set_mask(Lx*Ly)\n",
    "        self.to(device)\n",
    "        \n",
    "    def set_mask(self, L):\n",
    "        # take the log of a lower triangular matrix\n",
    "        self.L=L\n",
    "        self.mask = torch.log(torch.tril(torch.ones(L,L))).to(device)\n",
    "        self.pe.L=L\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input is shape [B,L,1]\n",
    "        # add positional encoding to get shape [B,L,Nh]\n",
    "        if input.shape[1]!=self.L:\n",
    "            self.set_mask(input.shape[1])\n",
    "        \n",
    "        input=self.pe(input).transpose(1,0)\n",
    "        output = self.transformer(input,self.mask)\n",
    "        output = self.lin(output.transpose(1,0))\n",
    "        return output\n",
    "    \n",
    "    \n",
    "    def logprobability(self,input):\n",
    "        \"\"\"Compute the logscale probability of a given state\n",
    "            Inputs:\n",
    "                input - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "            Returns:\n",
    "                logp - [B] size vector of logscale probability labels\n",
    "        \"\"\"\n",
    "        \n",
    "        #Input should have shape [B,L,1]\n",
    "        B,L,one=input.shape\n",
    "        \n",
    "        #first prediction is with the zero input vector\n",
    "        data=torch.zeros([B,L,one],device=self.device)\n",
    "        #data is the input vector shifted one to the right, with the very first entry set to zero instead of using pbc\n",
    "        data[:,1:,:]=input[:,:-1,:]\n",
    "        \n",
    "        #real is going to be a set of actual values\n",
    "        real=input\n",
    "        #and pred is going to be a set of probabilities\n",
    "        #if real[i]=1 than you multiply your conditional probability by pred[i]\n",
    "        #if real[i]=0 than you multiply by 1-pred[i]\n",
    "        \n",
    "        #probability predictions may be done WITH gradients\n",
    "        #with torch.no_grad():\n",
    "        \n",
    "        pred = self.forward(data)\n",
    "        ones = real*pred\n",
    "        zeros=(1-real)*(1-pred)\n",
    "        total = ones+zeros\n",
    "        #this is the sum you see in the cell above\n",
    "        #add 1e-10 to the prediction to avoid nans when total=0\n",
    "        logp=torch.sum(torch.log(total+1e-10),dim=1).squeeze(1)\n",
    "        return logp\n",
    "    def sample(self,B,L):\n",
    "        \"\"\" Generates a set states\n",
    "        Inputs:\n",
    "            B (int)            - The number of states to generate in parallel\n",
    "            L (int)            - The length of generated vectors\n",
    "        Returns:\n",
    "            samples - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "        \"\"\"\n",
    "        \n",
    "        #Sample set will have shape [B,L,1]\n",
    "        #need one extra zero batch at the start for first pred hence input is [N,L+1,1] \n",
    "        input = torch.zeros([B,L+1,1],device=self.device)\n",
    "        \n",
    "        #self.set_mask(L)\n",
    "        #sampling can be done without gradients\n",
    "        with torch.no_grad():\n",
    "          for idx in range(1,L+1):\n",
    "            #run the rnn on shape [B,1,1]   \n",
    "            #encode the input to the proper shape\n",
    "            encoded_input = input[:,:idx,:]+self.pe.pe[:,:idx,:]\n",
    "                        \n",
    "            #Get transformer output\n",
    "            output = self.transformer(encoded_input.transpose(1,0),self.mask[:idx,:idx])\n",
    "            #if probs[i]=1 then there should be a 100% chance that sample[i]=1\n",
    "            #if probs[i]=0 then there should be a 0% chance that sample[i]=1\n",
    "            #stands that we generate a random uniform u and take int(u<probs) as our sample\n",
    "            probs=self.lin(output.transpose(1,0)[:,-1,:])\n",
    "            sample = (torch.rand([B,1],device=device)<probs).to(torch.float32)\n",
    "            input[:,idx,:]=sample\n",
    "        #input's first entry is zero to get a predction for the first atom\n",
    "        return input[:,1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4602efb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastTransformer(SlowTransformer):\n",
    "    \n",
    "    def next_attn(_,tgt,layer):\n",
    "        \"\"\"Calculates self attention with tgt and the last elem of tgt\n",
    "        Inputs: \n",
    "            tgt - Tensor of shape [L+1,B,1]\n",
    "            layer - TransformerDecoderLayer\n",
    "        Outputs:\n",
    "            Tensor of shape [1,B,1]\n",
    "        \"\"\"\n",
    "        src = tgt[-1:, :, :]\n",
    "\n",
    "        # self attention part\n",
    "        src2 = layer.self_attn(\n",
    "            src,#only do attention with the last elem of the sequence\n",
    "            tgt,\n",
    "            tgt,\n",
    "            attn_mask=None,  # not needed because we only care about the last token\n",
    "            key_padding_mask=None,\n",
    "        )[0]\n",
    "        #straight from torch transformer encoder code\n",
    "        src = src + layer.dropout1(src2)\n",
    "        src = layer.norm1(src)\n",
    "        src2 = layer.linear2(layer.dropout(layer.activation(layer.linear1(src))))\n",
    "        src = src + layer.dropout2(src2)\n",
    "        src = layer.norm2(src)\n",
    "        return src\n",
    "    \n",
    "    def next_with_cache(self,tgt,cache=None):\n",
    "        \"\"\"Efficiently calculates the next output of a transformer given the input sequence and \n",
    "        cached intermediate layer encodings of the input sequence\n",
    "        \n",
    "        Inputs:\n",
    "            tgt - Tensor of shape [L+1,B,1]\n",
    "            cache - Tensor of shape ?\n",
    "            \n",
    "        Outputs:\n",
    "            output - Tensor of shape [?,B,1]\n",
    "            new_cache - Tensor of shape ?\n",
    "        \"\"\"\n",
    "        output = tgt\n",
    "        new_token_cache = []\n",
    "        #go through each layer and apply self attention only to the last input\n",
    "        for i, layer in enumerate(self.transformer.layers):\n",
    "            output = self.next_attn(output,layer)\n",
    "            new_token_cache.append(output)\n",
    "            if cache is not None:\n",
    "                #layers after layer 1 need to use a cache of the previous layer's output on each input\n",
    "                output = torch.cat([cache[i], output], dim=0)\n",
    "\n",
    "        #update cache with new output\n",
    "        if cache is not None:\n",
    "            new_cache = torch.cat([cache, torch.stack(new_token_cache, dim=0)], dim=1)\n",
    "        else:\n",
    "            new_cache = torch.stack(new_token_cache, dim=0)\n",
    "\n",
    "        return output, new_cache\n",
    "    \n",
    "    def set_mask(self, L):\n",
    "        # take the log of a lower triangular matrix\n",
    "        self.L=L\n",
    "        self.mask = torch.log(torch.tril(torch.ones(L,L))).to(device)\n",
    "        self.pe.L=L\n",
    "        self.pe_t = self.pe.pe.transpose(1,0)\n",
    "    \n",
    "    \n",
    "    def sample(self,B,L):\n",
    "        \"\"\" Generates a set states\n",
    "        Inputs:\n",
    "            B (int)            - The number of states to generate in parallel\n",
    "            L (int)            - The length of generated vectors\n",
    "        Returns:\n",
    "            samples - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "        \"\"\"\n",
    "        #return (torch.rand([B,L,1],device=device)<0.5).to(torch.float32)\n",
    "        #Sample set will have shape [B,L,1]\n",
    "        #need one extra zero batch at the start for first pred hence input is [L+1,B,1] \n",
    "        #transformers don't do batch first so to save a bunch of transpose calls \n",
    "        input = torch.zeros([L+1,B,1],device=self.device)\n",
    "        #self.set_mask(L)\n",
    "        \n",
    "        cache=None\n",
    "        with torch.no_grad():\n",
    "          for idx in range(1,L+1):\n",
    "            #run the rnn on shape [B,1,1]   \n",
    "            #encode the input to the proper shape\n",
    "            encoded_input = input[:idx,:,:]+self.pe_t[:idx,:,:]\n",
    "                        \n",
    "            #Get transformer output\n",
    "            output,cache = self.next_with_cache(encoded_input,cache)\n",
    "            #if probs[i]=1 then there should be a 100% chance that sample[i]=1\n",
    "            #if probs[i]=0 then there should be a 0% chance that sample[i]=1\n",
    "            #stands that we generate a random uniform u and take int(u<probs) as our sample\n",
    "            probs=self.lin(output[-1,:,:])\n",
    "            sample = (torch.rand([B,1],device=device)<probs).to(torch.float32)\n",
    "            input[idx,:,:]=sample\n",
    "        #input's first entry is zero to get a predction for the first atom\n",
    "        #print(\".\",end=\"\")\n",
    "        return input.transpose(1,0)[:,1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7403eb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L                             \t\t\t64\n",
      "Q                             \t\t\t1\n",
      "K                             \t\t\t32\n",
      "B                             \t\t\t32\n",
      "TOL                           \t\t\t0.15\n",
      "M                             \t\t\t0.96875\n",
      "USEQUEUE                      \t\t\t0\n",
      "NLOOPS                        \t\t\t1\n",
      "hamiltonian                   \t\t\tRydberg\n",
      "steps                         \t\t\t12000\n",
      "dir                           \t\t\tout\n",
      "Nh                            \t\t\t64\n",
      "lr                            \t\t\t0.0005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Settings\n",
    "op=Opt()\n",
    "Lx=8\n",
    "op.L=Lx*Lx\n",
    "op.Nh=64\n",
    "op.lr=5e-4\n",
    "op.Q=1\n",
    "op.K=32\n",
    "op.USEQUEUE=0\n",
    "#op.apply(sys.argv[1:])\n",
    "op.B=op.K*op.Q\n",
    "print(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f9a845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsformer = FastTransformer(Lx,Lx,Nh=op.Nh,num_layers=2)\n",
    "sampleformer= FastTransformer(Lx,Lx,Nh=op.Nh,num_layers=2)\n",
    "beta1=0.9;beta2=0.999\n",
    "optimizer = torch.optim.Adam(\n",
    "trainsformer.parameters(), \n",
    "lr=op.lr, \n",
    "betas=(beta1,beta2)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1119cc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847681\n"
     ]
    }
   ],
   "source": [
    "print(sum (p.numel () for p in trainsformer.parameters ()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f415335d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training. . .\n",
      "Output folder path established\n",
      "-0.40522 64\n",
      "1,1.53|92,-0.33|185,-0.32|278,-0.34|370,-0.36|463,-0.35|555,-0.38|648,-0.42|740,-0.40|832,-0.41|925,-0.41|1034,-0.41|1149,-0.40|1263,-0.41|1378,-0.41|1494,-0.41|1608,-0.41|1722,-0.41|1837,-0.41|1951,-0.41|2066,-0.41|2164,-0.40|2257,-0.41|2351,-0.41|2444.6738176345825 12000\n"
     ]
    }
   ],
   "source": [
    "#op.steps=4000\n",
    "op.dir=\"TFF\"\n",
    "\n",
    "if op.USEQUEUE:\n",
    "    queue_train(op,(trainsformer,sampleformer,optimizer))\n",
    "else:\n",
    "    print(\"Training. . .\")\n",
    "    reg_train(op,(trainsformer,optimizer))\n",
    "    #reg_train(op,(super(FastTransformer, trainsformer),optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7516974f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size 32:\n",
      "old:  3.984227418899536\n",
      "new:  3.6998283863067627\n",
      "Batch size 320:\n",
      "old:  25.44533944129944\n",
      "new:  4.284188985824585\n"
     ]
    }
   ],
   "source": [
    "print(\"Batch size 32:\")\n",
    "\n",
    "t=time.time()\n",
    "for x in range(50):\n",
    "    super(FastTransformer, trainsformer).sample(32,op.L)\n",
    "print(\"old: \",time.time()-t)\n",
    "\n",
    "t=time.time()\n",
    "for x in range(50):\n",
    "    trainsformer.sample(32,op.L)\n",
    "print(\"new: \",time.time()-t)\n",
    "\n",
    "print(\"Batch size 320:\")\n",
    "\n",
    "t=time.time()\n",
    "for x in range(50):\n",
    "    super(FastTransformer, trainsformer).sample(320,op.L)\n",
    "print(\"old: \",time.time()-t)\n",
    "\n",
    "t=time.time()\n",
    "for x in range(50):\n",
    "    trainsformer.sample(320,op.L)\n",
    "print(\"new: \",time.time()-t)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4378195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 1])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAADICAYAAADx97qTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPkUlEQVR4nO3df6xkZX3H8ffHZYWKGncRyC1sizXU1hhZzA1oaIyVUpGYQpvYSFNjE5L1D02gMVGwSUv7T0mq/fFHY7JWKk2trUGtxhgRqY0xMeouIoIrsm23urJlEdoIbUIAv/3jnm0v69y9c+fMmZln7vuV3MzMc2fO+T7nnPvd2fM9z3lSVUiS2vOceQcgSZqMCVySGmUCl6RGmcAlqVEmcElqlAlckhrVK4EnuTLJA0kOJ7lxWkFJkjaXSa8DT7ID+C5wBXAU+DpwbVV9e6PPPDen1xmcuemyf/6V/zOy/bv3Pm+iWLdq1PqHWPdW1jOrmLS5vvtio+O7zzI1vHnmhYP3PvnDqjr75PY+Cfw1wM1V9Ybu9U0AVfXHG33mhdldl+byTZd9x0P3jGx/w0/vnSDSrRu1/iHWvZX1zComba7vvtjo+O6zTA1vnnlhx8rhg1W1enJ7n1Mo5wHfX/f6aNcmSZqB03p8NiPafuLrfJJ9wD6AM/C/hJI0LX2+gR8F9qx7fT7w0Mlvqqr9VbVaVas7Ob3H6iRJ6/X5Bv514MIkLwF+ALwF+K2pRDVnszr3uJX19IlpO58/H7fvW6m7DLHttsv+aMG8a3Cj13N45HsnTuBV9XSSdwJ3ADuAW6vq/kmXJ0namj7fwKmqzwKfnVIskqQtcCSmJDXKBC5JjZp4IM8kxh3Is5HtUIybdwFlCNthv0lD+kLdPvWBPJKkOTKBS1KjTOCS1CgTuCQ1ygQuSY1q6iqUls3zSgyvApkut2ebhritQp/1bIVXoUjSkjGBS1KjTOCS1CgTuCQ1au5FzHnOMzfUurT9DDFP5rIdm/4NTs4ipiQtGRO4JDXKBC5Jjeo1I0+SI8DjwDPA06PO0UiShtGriNkl8NWq+uE471+96Iz62h17ntW2XQoYrRSphoizlb5r+9nKsdlnJKcjMSVJz9I3gRfw+SQHk+ybRkCSpPH0OgcOXFZVDyU5B7gzyXeq6kvr39Al9n0AP3Ne39VJkk7o9Q28qh7qHo8DnwQuGfGe/VW1WlWrZ5+1o8/qJEnrTFzETHIm8Jyqerx7fifwR1X1uY0+M8+RmLO0jH2SNrJsx/sQI0b7LnOjImafcxrnAp9McmI5f3eq5C1Jmq6JE3hV/Stw0RRjkSRtgZcRSlKjTOCS1CgTuCQ1au73Ax/Cdrk3cytxDmHafV/EiWwX0RDDyftsu+1yj3GH0kvSkjGBS1KjTOCS1CgTuCQ1qvkiZsvFo+1SbB1lO9x3fN4FtkXbHpqcRUxJWjImcElqlAlckhplApekRjU1Rc6yFWX6xu4owWdbtD7NsiC9aKMZt8sx11ff7eQ3cElqlAlckhplApekRpnAJalRm47ETHIr8CbgeFW9omvbDfwDcAFwBPjNqvrPzVY27kjMeY9gk5bVIhYXFzGmPoYoSO9YOTzxSMwPA1ee1HYjcFdVXQjc1b2WJM3Qpgm8qr4EPHZS89XAbd3z24BrphuWJGkzk54DP7eqjgF0j+ds9MYk+5IcSHLgKZ6ccHWSpJMNXsSsqv1VtVpVqzs5fejVSdK2MWkCfzjJCkD3eHx6IUmSxjHpUPpPA28DbukePzW1iBhm8lPNz3bdb4t4NdW4ExBv9N4+FnF7jNI3zr7bePR6Do/8/KbfwJN8FPgK8LIkR5Ncx1riviLJg8AV3WtJ0gxt+g28qq7d4FfTnVpHkrQljsSUpEaZwCWpUQt5P/BWih3SqbRSjN/Of1db2Rd99ttQ29hv4JLUKBO4JDXKBC5JjTKBS1KjFrKIOcQJ/+1SGJ1ngWy7bON5ankbL2KMW4lp2pM8910m+A1ckpplApekRpnAJalRJnBJatSmkxpP07iTGm9k0UawbRdu9+ENsY3nucxZjXDcSCvLHNcX6vaJJzWWJC0gE7gkNcoELkmNMoFLUqPGmVLt1iTHk9y3ru3mJD9Ick/3c9WwYUqSTrbpVShJXgs8AfxNVb2ia7sZeKKq3reVlY17FUrLw4W1PfW9QmFWVzh4RVGbJr4Kpaq+BDw2SFSSpIn1OQf+ziT3dqdYdm30piT7khxIcuApnuyxOknSepMm8A8ALwX2AseA92/0xqraX1WrVbW6k9MnXJ0k6WQTJfCqeriqnqmqHwMfBC6ZbliSpM1MdD/wJCtVdax7+evAfad6/6nMu6gyxNBgbW7Rtmffwnnf2Mf9/LzjHKWVAu4y2jSBJ/ko8DrgxUmOAn8AvC7JXqCAI8DbhwtRkjTKpgm8qq4d0fyhAWKRJG2BIzElqVEmcElq1EzvB7560Rn1tTv2PKttEYsVFlUWx7xH5S7asTDL7THtvs97X45rEeP0fuCStGRM4JLUKBO4JDXKBC5JjbKIOYBFK3yNsoiFmnlye0yuheO9dRYxJWnJmMAlqVEmcElqlAlckhplApekRs30KpRRkxpbwdYiGOIqlFaubJl3nEPkgD7LXMTtsWPlsFehSNIyMYFLUqNM4JLUqE0TeJI9Sb6Y5FCS+5Nc37XvTnJnkge7x13DhytJOmHTImaSFWClqu5O8gLgIHAN8DvAY1V1S5IbgV1V9Z5TLWtWQ+m3UsCwiCqYf+FKbZpV/ph4KH1VHauqu7vnjwOHgPOAq4HburfdxlpSlyTNyJbOgSe5ALgY+CpwblUdg7UkD5wz9egkSRsaO4EneT7wceCGqvrRFj63L8mBJAceefSZSWKUJI0wVgJPspO15P2RqvpE1/xwd378xHny46M+W1X7q2q1qlbPPmvHNGKWJDFeETOsneN+rKpuWNf+J8Cj64qYu6vq3adaVt+RmBYcdSoeH9tP68XncY/ZjYqYp42xjsuAtwLfSnJibe8FbgE+luQ64HvAm8eMWZI0BZsm8Kr6MpANfn35Bu2SpIE5ElOSGmUCl6RGjXMOfFCtFBu0+EYdS+MWifoWw+ZdQJ33+uel9Qsexj0Wd6yM/rzfwCWpUSZwSWqUCVySGmUCl6RGmcAlqVEzndR4iPuBz+oqg2WziNtjEa8cmOfkuIs22e+8tRx7XxPfD1yStJhM4JLUKBO4JDXKBC5JjWqqiLmdixjjchsNz208XW7PzVnElKQlYwKXpEaZwCWpUZsm8CR7knwxyaEk9ye5vmu/OckPktzT/Vw1fLiSpBPGuR/408C7quruJC8ADia5s/vdn1XV+4YL79mGKGwsWwFlVrEv23bbinmOHt4u23iUeW+PWa1/K/cDH2dOzGPAse7540kOAef1CVCS1N+WzoEnuQC4GPhq1/TOJPcmuTXJrmkHJ0na2NgJPMnzgY8DN1TVj4APAC8F9rL2Df39G3xuX5IDSQ488ugz/SOWJAFjJvAkO1lL3h+pqk8AVNXDVfVMVf0Y+CBwyajPVtX+qlqtqtWzz9oxrbgladvbdCRmkgC3AY9V1Q3r2le68+Mk+V3g0qp6y6mWNcTtZBfRvIstOrWW988i3gZ42cx7G48uYh4eORJznKtQLgPeCnwryYklvxe4NsleoIAjwNsnilaSNJFxrkL5MpARv/rs9MORJI3LkZiS1CgTuCQ1ygQuSY2a6f3AX5jddWku3/R9W6kCt3xFgSbnfl9sLe+fRcw/3g9ckpaMCVySGmUCl6RGmcAlqVELWcTcSMuFEbWp5WNu0WKf9xD1URZtG23EIqYkLRkTuCQ1ygQuSY0ygUtSo+ZexGyliDBv095Oi1hQWjaLuI37Hkfz/HvdzrnCIqYkLRkTuCQ1ygQuSY3aNIEnOSPJ15J8M8n9Sf6wa9+d5M4kD3aPu4YPV5J0wriTGp9ZVU90s9N/Gbge+A3WJjq+JcmNwK6qes+pltV3JOYQlq0wsmz92YpZ9X27bOMW+rmIheIhTFzErDVPdC93dj8FXM3abPV0j9dMJ1RJ0jjGOgeeZEc3I/1x4M6q+ipwblUdA+gezxksSknSTxgrgVfVM1W1FzgfuCTJK8ZdQZJ9SQ4kOfAUT04YpiTpZFu6CqWq/gv4Z+BK4OEkKwDd4/ENPrO/qlaranUnp/eLVpL0f8a5CuXsJC/qnv8U8CvAd4BPA2/r3vY24FMDxShJGuG0Md6zAtyWZAdrCf9jVfWZJF8BPpbkOuB7wJsHjHNDLVTKZ2kR+z7uPtrKvpznfl+0ofAwTEyLdiy1cnz0NSr2HSuj37tpAq+qe4GLR7Q/CizWNYGStI04ElOSGmUCl6RGmcAlqVEzvR94kkeAf+9evhj44cxWPjz7s/iWrU/2Z7FNsz8/W1Vnn9w40wT+rBUnB0aN7W+V/Vl8y9Yn+7PYZtEfT6FIUqNM4JLUqHkm8P1zXPcQ7M/iW7Y+2Z/FNnh/5nYOXJLUj6dQJKlRM0/gSa5M8kCSw91MPs1JcmuS40nuW9fW7BRzSfYk+WKSQ920edd37U32aVmnAezuy/+NJJ/pXrfenyNJvpXkniQHurZm+5TkRUluT/Kd7m/pNUP3Z6YJvLsh1l8CbwReDlyb5OWzjGFKPszaLXXXuxG4q6ouBO7qXrfiaeBdVfWLwKuBd3T7pdU+PQm8vqouAvYCVyZ5Ne3254TrgUPrXrfeH4Bfrqq96y63a7lPfwF8rqp+AbiItX01bH+qamY/wGuAO9a9vgm4aZYxTLEvFwD3rXv9ALDSPV8BHph3jD369ingimXoE/A84G7g0pb7w9pkKncBrwc+07U1258u5iPAi09qa7JPwAuBf6OrK86qP7M+hXIe8P11r492bctgKaaYS3IBa3efbHravCWcBvDPgXcDP17X1nJ/YG1u3c8nOZhkX9fWap9+DngE+OvuNNdfJTmTgfsz6wSeEW1eBrMgkjwf+DhwQ1X9aN7x9FE9pgFcNEneBByvqoPzjmXKLquqV7F2SvUdSV4774B6OA14FfCBqroY+G9mcPpn1gn8KLBn3evzgYdmHMNQxppiblEl2cla8v5IVX2ia266TzDZNIAL6DLg15IcAf4eeH2Sv6Xd/gBQVQ91j8eBTwKX0G6fjgJHu//pAdzOWkIftD+zTuBfBy5M8pIkzwXewtrUbMug2SnmkgT4EHCoqv503a+a7NOyTQNYVTdV1flVdQFrfzP/VFW/TaP9AUhyZpIXnHgO/CpwH432qar+A/h+kpd1TZcD32bo/szhZP9VwHeBfwF+b97Fhwn78FHgGPAUa//yXgecxVqR6cHucfe849xCf36JtVNZ9wL3dD9Xtdon4JXAN7r+3Af8ftfeZH9O6tvr+P8iZrP9Ye2c8Te7n/tP5ILG+7QXONAdd/8I7Bq6P47ElKRGORJTkhplApekRpnAJalRJnBJapQJXJIaZQKXpEaZwCWpUSZwSWrU/wJIZGJS0u0sWgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 1])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    #trainsformer = FastTransformer(Lx,Lx,Nh=op.Nh,num_layers=2)\n",
    "    torch.random.manual_seed(7)\n",
    "    s = trainsformer.sample(op.B,op.L)\n",
    "    print(s.shape)\n",
    "    plt.imshow(s[:,:,0].cpu())\n",
    "    plt.show()\n",
    "    torch.random.manual_seed(7)\n",
    "    s2 = super(FastTransformer, trainsformer).sample(op.B,op.L)\n",
    "    print(s2.shape)\n",
    "    plt.imshow(s2[:,:,0].cpu())\n",
    "    plt.show()\n",
    "    print(torch.sum(abs(s2-s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55984674",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847774\n",
      "Output folder path established\n",
      "-0.40522 64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-7fdee4bb667f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrainrnn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_rnn_with_optim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"GRU\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m459\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrainrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mreg_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainrnn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Python Scripts\\ResearchF2022\\NN-QSR\\RNN_QSR.py\u001b[0m in \u001b[0;36mreg_train\u001b[1;34m(op, to)\u001b[0m\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m         \u001b[1;31m#gather samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         \u001b[0mfill_queue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m         \u001b[1;31m# get probability labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m         \u001b[0mlogp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogprobability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamplequeue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\ResearchF2022\\NN-QSR\\RNN_QSR.py\u001b[0m in \u001b[0;36mfill_queue\u001b[1;34m()\u001b[0m\n\u001b[0;32m    698\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfill_queue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 700\u001b[1;33m             \u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msump\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msqrtp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_with_labelsALT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnloops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNLOOPS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    701\u001b[0m             \u001b[0msamplequeue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m             \u001b[0msump_queue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msump\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\ResearchF2022\\NN-QSR\\RNN_QSR.py\u001b[0m in \u001b[0;36msample_with_labelsALT\u001b[1;34m(self, B, L, grad, nloops)\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[0msumsqrtp\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msize\u001b[0m \u001b[0mB\u001b[0m \u001b[0mvector\u001b[0m \u001b[0mof\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlogsqrtp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;31m'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \"\"\"\n\u001b[1;32m--> 260\u001b[1;33m         \u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_with_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnloops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m         \u001b[1;31m#get the average of our logprobabilities and divide by 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[0mlogsqrtp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\ResearchF2022\\NN-QSR\\RNN_QSR.py\u001b[0m in \u001b[0;36msample_with_labels\u001b[1;34m(self, B, L, grad, nloops)\u001b[0m\n\u001b[0;32m    225\u001b[0m                     \u001b[0mrelative\u001b[0m \u001b[0mto\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \"\"\"\n\u001b[1;32m--> 227\u001b[1;33m         \u001b[0msample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_off_diag_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnloops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\ResearchF2022\\NN-QSR\\RNN_QSR.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, B, L)\u001b[0m\n\u001b[0;32m    372\u001b[0m             \u001b[1;31m#run the rnn on shape [B,1,1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m             \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m             \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m             \u001b[1;31m#if probs[i]=1 then there should be a 100% chance that sample[i]=1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    848\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 850\u001b[1;33m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    851\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train a gru\n",
    "op.dir=\"GRU\"\n",
    "trainrnn,optimizer=new_rnn_with_optim(\"GRU\",459,lr=op.lr)\n",
    "print(sum (p.numel () for p in trainrnn.parameters ()))\n",
    "reg_train(op,(trainrnn,optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5b7dcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413121\n",
      "Output folder path established\n",
      "-0.45776822 16\n",
      "0,2.01|5,-0.38|10,-0.42|15,-0.44|20,-0.45|25,-0.45|31,-0.45|36,-0.45|41,-0.46|46,-0.45|51,-0.46|56,-0.45|61,-0.45|66,-0.46|71,-0.46|76,-0.46|82,-0.46|87,-0.44|92,-0.45|97,-0.46|102,-0.46|107,-0.45|112,-0.45|117,-0.46|122.32494974136353 12000\n"
     ]
    }
   ],
   "source": [
    "Lx=4\n",
    "op.L=Lx*Lx\n",
    "op.dir=\"GRU\"\n",
    "trainrnn,optimizer=new_rnn_with_optim(\"GRU\",320,lr=op.lr)\n",
    "print(sum (p.numel () for p in trainrnn.parameters ()))\n",
    "reg_train(op,(trainrnn,optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32ea5f78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training. . .\n",
      "Output folder path established\n",
      "-0.40522 64\n",
      "0,2.38|133,-0.31|267,-0.30|400,-0.35|536,-0.37|670,-0.40|804,-0.41|938,-0.41|1072,-0.41|1206,-0.40|1340,-0.41|1474,-0.41|1609,-0.41|1743,-0.41|1877,-0.41|2011,-0.41|2146,-0.41|2285,-0.42|2426,-0.41|2560,-0.40|2695,-0.41|2829,-0.41|2963,-0.41|3097,-0.41|3231.5833308696747 12000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#op.steps=4000\n",
    "op.dir=\"TF\"\n",
    "\n",
    "\n",
    "if op.USEQUEUE:\n",
    "    queue_train(op,(trainsformer,sampleformer,optimizer))\n",
    "else:\n",
    "    print(\"Training. . .\")\n",
    "    reg_train(op,(trainsformer,optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d524bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  1.,  1.,  1.],\n",
       "         [ 2.,  2.,  2.,  2.],\n",
       "         [ 3.,  3.,  3.,  3.],\n",
       "         [ 4.,  4.,  4.,  4.]],\n",
       "\n",
       "        [[ 5.,  5.,  5.,  5.],\n",
       "         [ 6.,  6.,  6.,  6.],\n",
       "         [ 7.,  7.,  7.,  7.],\n",
       "         [ 8.,  8.,  8.,  8.]],\n",
       "\n",
       "        [[ 9.,  9.,  9.,  9.],\n",
       "         [10., 10., 10., 10.],\n",
       "         [11., 11., 11., 11.],\n",
       "         [12., 12., 12., 12.]],\n",
       "\n",
       "        [[13., 13., 13., 13.],\n",
       "         [14., 14., 14., 14.],\n",
       "         [15., 15., 15., 15.],\n",
       "         [16., 16., 16., 16.]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(4*4).reshape([4,4,1]) + torch.ones([1,4,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ec01ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 36, 40]) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "pe = PE2D(40,6,6,torch.device('cpu')).pe\n",
    "print(pe.shape,pe.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2714445c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ff48262d88>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pe[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3780fac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros([1,2,3]).transpose(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc274ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
