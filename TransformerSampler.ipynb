{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a30b9c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from RNN_QSR import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02694a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PE2D(nn.Module):\n",
    "    \"\"\"Positional Encoder for a 2D sequence\"\"\"\n",
    "    #TODO: Positional encoding is wrong because the spins are at index i+1 when we sample and get probabilities\n",
    "    def __init__(self, d_model, Lx,Ly,device,n_encode=None):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            Lx (int) -- Size in the x dimension (axis 1)\n",
    "            Ly (int) -- Size in the y dimension (axis 2)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # create constant 'pe' matrix with values dependant on \n",
    "        # pos and i\n",
    "        pe = torch.zeros(Lx*Ly, d_model)\n",
    "        \n",
    "        if type(n_encode)==type(None):\n",
    "            n_encode=3*d_model//4\n",
    "        for pos in range(Lx*Ly):\n",
    "            x=pos//Ly\n",
    "            y=pos%Ly\n",
    "            # Only going to fill 3/4 of the matrix so the\n",
    "            # occupation values are preserved\n",
    "            for i in range(0, n_encode, 4):\n",
    "                \n",
    "                #x direction encoding\n",
    "                pe[pos, i] = \\\n",
    "                math.sin(x / (10000 ** ((2 * i)/n_encode)))\n",
    "                pe[pos, i + 1] = \\\n",
    "                math.cos(x / (10000 ** ((2 * (i + 1))/n_encode)))\n",
    "                #y direction encoding\n",
    "                pe[pos, i+2] = \\\n",
    "                math.sin(y / (10000 ** ((2 * i)/n_encode)))\n",
    "                pe[pos, i + 3] = \\\n",
    "                math.cos(y / (10000 ** ((2 * (i + 1))/n_encode)))\n",
    "                \n",
    "        self.pe = pe.unsqueeze(0).to(device)\n",
    "        self.L=Lx*Ly\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Adds a positional encoding (batch first)\"\"\"\n",
    "        return x + self.pe[:,:self.L,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "406b661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlowTransformer(Sampler):\n",
    "    \"\"\"A transformer sampler which uses masked attention to calculate probabilities of a given state.\n",
    "    Here each 'spin' is given a positional encoding and self-attention is calculated across each spin and all  previous spins\n",
    "    \"\"\"\n",
    "    def __init__(self,Lx,Ly,device=device,Nh=128,decoder=False,dropout=0.0,num_layers=3,nhead=8, **kwargs):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            Lx,Ly (int) -- Sequence dimensions\n",
    "            Nh (int) -- size of the input vector at each sequence element (same as d_model)\n",
    "            decoder (bool) -- whether to use a TF decoder or encoder. Using a decoder isn't currently implemented\n",
    "        \"\"\"\n",
    "        super(SlowTransformer, self).__init__(device=device)\n",
    "        \n",
    "        self.pe = PE2D(Nh, Lx,Ly,device)\n",
    "        \n",
    "        if decoder:\n",
    "            #Decoder only transformer\n",
    "            self.decoder_layer = nn.TransformerDecoderLayer(d_model=Nh, nhead=nhead, dropout=dropout)\n",
    "            self.transformer = nn.TransformerDecoder(self.decoder_layer, num_layers=num_layers)\n",
    "        else:\n",
    "            #Encoder only transformer\n",
    "            #misinterperetation on encoder made it so this code does not work\n",
    "            self.encoder_layer = nn.TransformerEncoderLayer(d_model=Nh, nhead=nhead, dropout=dropout)\n",
    "            self.transformer = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)        \n",
    "        \n",
    "        self.lin = nn.Sequential(\n",
    "                nn.Linear(Nh,Nh),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(Nh,1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "        \n",
    "        self.set_mask(Lx*Ly)\n",
    "        self.to(device)\n",
    "        \n",
    "    def set_mask(self, L):\n",
    "        \"\"\"Initialize the self-attention mask\"\"\"\n",
    "        # take the log of a lower triangular matrix\n",
    "        self.L=L\n",
    "        self.mask = torch.log(torch.tril(torch.ones([L,L],device=self.device)))\n",
    "        self.pe.L=L\n",
    "\n",
    "    def forward(self, input):\n",
    "        \n",
    "        # input is shape [B,L,1]\n",
    "        # add positional encoding to get shape [B,L,Nh]\n",
    "        if input.shape[1]!=self.L:\n",
    "            self.set_mask(input.shape[1])\n",
    "        \n",
    "        input=self.pe(input).transpose(1,0)\n",
    "        output = self.transformer(input,self.mask)\n",
    "        output = self.lin(output.transpose(1,0))\n",
    "        return output\n",
    "    \n",
    "    \n",
    "    def logprobability(self,input):\n",
    "        \"\"\"Compute the logscale probability of a given state\n",
    "            Inputs:\n",
    "                input - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "            Returns:\n",
    "                logp - [B] size vector of logscale probability labels\n",
    "        \"\"\"\n",
    "        \n",
    "        #Input should have shape [B,L,1]\n",
    "        B,L,one=input.shape\n",
    "        \n",
    "        #first prediction is with the zero input vector\n",
    "        data=torch.zeros([B,L,one],device=self.device)\n",
    "        #data is the input vector shifted one to the right, with the very first entry set to zero instead of using pbc\n",
    "        data[:,1:,:]=input[:,:-1,:]\n",
    "        \n",
    "        #real is going to be a set of actual values\n",
    "        real=input\n",
    "        #and pred is going to be a set of probabilities\n",
    "        #if real[i]=1 than you multiply your conditional probability by pred[i]\n",
    "        #if real[i]=0 than you multiply by 1-pred[i]\n",
    "        \n",
    "        #probability predictions may be done WITH gradients\n",
    "        #with torch.no_grad():\n",
    "        \n",
    "        pred = self.forward(data)\n",
    "        ones = real*pred\n",
    "        zeros=(1-real)*(1-pred)\n",
    "        total = ones+zeros\n",
    "        #this is the sum you see in the cell above\n",
    "        #add 1e-10 to the prediction to avoid nans when total=0\n",
    "        logp=torch.sum(torch.log(total+1e-10),dim=1).squeeze(1)\n",
    "        return logp\n",
    "    def sample(self,B,L):\n",
    "        \"\"\" Generates a set states\n",
    "        Inputs:\n",
    "            B (int)            - The number of states to generate in parallel\n",
    "            L (int)            - The length of generated vectors\n",
    "        Returns:\n",
    "            samples - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "        \"\"\"\n",
    "        \n",
    "        #Sample set will have shape [B,L,1]\n",
    "        #need one extra zero batch at the start for first pred hence input is [N,L+1,1] \n",
    "        input = torch.zeros([B,L+1,1],device=self.device)\n",
    "        \n",
    "        self.set_mask(L)\n",
    "        #sampling can be done without gradients\n",
    "        with torch.no_grad():\n",
    "          for idx in range(1,L+1):\n",
    "            #run the rnn on shape [B,1,1]   \n",
    "            #encode the input to the proper shape\n",
    "            encoded_input = input[:,:idx,:]+self.pe.pe[:,:idx,:]\n",
    "                        \n",
    "            #Get transformer output\n",
    "            output = self.transformer(encoded_input.transpose(1,0),self.mask[:idx,:idx])\n",
    "            #if probs[i]=1 then there should be a 100% chance that sample[i]=1\n",
    "            #if probs[i]=0 then there should be a 0% chance that sample[i]=1\n",
    "            #stands that we generate a random uniform u and take int(u\n",
    "            probs=self.lin(output.transpose(1,0)[:,-1,:])\n",
    "            sample = (torch.rand([B,1],device=device)<probs).to(torch.float32)\n",
    "            input[:,idx,:]=sample\n",
    "        #input's first entry is zero to get a predction for the first atom\n",
    "        return input[:,1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65a7e723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unused weight initialization\n",
    "def init_weights(self):\n",
    "    self.num_weights = sum (p.numel () for p in self.parameters ())\n",
    "    print(\"Initializing. . .\",self.num_weights)\n",
    "    stdv=10/np.sqrt(self.num_weights)\n",
    "    for weight in self.parameters():\n",
    "        nn.init.normal_(weight, mean=0.0,std= stdv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaf620b",
   "metadata": {},
   "source": [
    "# Modification of Source here:\n",
    "[Docs](https://virtualgroup.cn/pytorch.org/docs/stable/_modules/torch/nn/modules/transformer.html#TransformerEncoderLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4602efb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastTransformer(SlowTransformer):\n",
    "    \"\"\"Same architecture as SlowTransformer (weights can be shared) but with improvements to sampling and labelling which\n",
    "    can give a 2x performance boost\"\"\"\n",
    "    def _off_diag_labels(self,sample,B,L,grad,D=1): #_off_diag_labels\n",
    "        \"\"\"label all of the flipped states  - set D as high as possible without it slowing down runtime\n",
    "        Parameters:\n",
    "            sample - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "            B,L (int) - batch size and sequence length\n",
    "            D (int) - Number of partitions sequence-wise. We must have L%D==0 (D divides L)\n",
    "            \n",
    "        Outputs:\n",
    "            \n",
    "            sample - same as input\n",
    "            probs - [B,L] matrix of probabilities of states with the jth excitation flipped\n",
    "        \"\"\"\n",
    "        sflip = torch.zeros([B,L,L,1],device=self.device)\n",
    "        #collect all of the flipped states into one array\n",
    "        for j in range(L):\n",
    "            #get all of the states with one spin flipped\n",
    "            sflip[:,j] = sample*1.0\n",
    "            sflip[:,j,j] = 1-sflip[:,j,j]\n",
    "        #compute all of their logscale probabilities\n",
    "        with torch.no_grad():\n",
    "            #prepare sample to be used as cache\n",
    "            B,L,one=sample.shape\n",
    "            dsample=torch.zeros([B,L,one],device=self.device)\n",
    "            dsample[:,1:,:]=sample[:,:-1,:]\n",
    "\n",
    "            #add positional encoding and make the cache\n",
    "            out,cache=self.make_cache(self.pe(dsample).transpose(1,0))\n",
    "\n",
    "            probs=torch.zeros([B,L],device=self.device)\n",
    "            #expand cache to group L//D flipped states\n",
    "            cache=cache.unsqueeze(2)\n",
    "\n",
    "            #this line took like 1 hour to write I'm so sad\n",
    "            #the cache has to be shaped such that the batch parts line up\n",
    "            cache=cache.repeat(1,1,L//D,1,1).transpose(2,3).reshape(cache.shape[0],L,B*L//D,cache.shape[-1])\n",
    "\n",
    "            pred0 = self.lin(out.transpose(1,0))\n",
    "            ones = sample*pred0\n",
    "            zeros=(1-sample)*(1-pred0)\n",
    "            total0 = ones+zeros\n",
    "\n",
    "            for k in range(D):\n",
    "\n",
    "                N = k*L//D\n",
    "                #next couple of steps are crucial          \n",
    "                #get the samples from N to N+L//D\n",
    "                #Note: samples are the same as the original up to the Nth spin\n",
    "                real = sflip[:,N:(k+1)*L//D]\n",
    "                #flatten it out \n",
    "                tmp = real.reshape([B*L//D,L,1])\n",
    "                #set up next state predction\n",
    "                fsample=torch.zeros(tmp.shape,device=self.device)\n",
    "                fsample[:,1:,:]=tmp[:,:-1,:]\n",
    "                # put sequence before batch so you can use it with your transformer\n",
    "                tgt=self.pe(fsample).transpose(1,0)\n",
    "                #grab your transformer output\n",
    "                out,_=self.next_with_cache(tgt,cache[:,:N],N)\n",
    "\n",
    "                # self.lin actually does some repeated work but it's probably\n",
    "                # negligable compared to the time attention takes\n",
    "                output = self.lin(out[N:].transpose(1,0))\n",
    "                # reshape output separating batch from spin flip grouping\n",
    "                pred = output.view([B,L//D,L-N,1])\n",
    "                real=real[:,:,N:]\n",
    "                ones = real*pred\n",
    "                zeros=(1-real)*(1-pred)\n",
    "                total = ones+zeros\n",
    "                #sum across the sequence for probabilities\n",
    "                logp=torch.sum(torch.log(total+1e-10),dim=2).squeeze(2)\n",
    "                logp+=torch.sum(torch.log(total0[:,:N]+1e-10),dim=1)\n",
    "                probs[:,N:(k+1)*L//D]=logp\n",
    "                \n",
    "        return sample,probs\n",
    "    def next_attn(_,tgt,layer,i=-1):\n",
    "        \"\"\"Calculates self attention with tgt and the last elem of tgt\n",
    "        Inputs: \n",
    "            tgt - Tensor of shape [L+1,B,1]\n",
    "            layer - TransformerDecoderLayer\n",
    "            i - index of the first bit we want self-attention from\n",
    "        Outputs:\n",
    "            Tensor of shape [1,B,1]\n",
    "        \"\"\"\n",
    "        src = tgt[i:, :, :]\n",
    "        mask = None if i==-1 else _.mask[i:]\n",
    "        # self attention part\n",
    "        src2 = layer.self_attn(\n",
    "            src,#only do attention with the last elem of the sequence\n",
    "            tgt,\n",
    "            tgt,\n",
    "            attn_mask=mask,  # not needed because we only care about the last token\n",
    "            key_padding_mask=None,\n",
    "        )[0]\n",
    "        #straight from torch transformer encoder code\n",
    "        src = src + layer.dropout1(src2)\n",
    "        src = layer.norm1(src)\n",
    "        src2 = layer.linear2(layer.dropout(layer.activation(layer.linear1(src))))\n",
    "        src = src + layer.dropout2(src2)\n",
    "        src = layer.norm2(src)\n",
    "        return src\n",
    "    \n",
    "    def next_with_cache(self,tgt,cache=None,idx=-1):\n",
    "        \"\"\"Efficiently calculates the next output of a transformer given the input sequence and \n",
    "        cached intermediate layer encodings of the input sequence\n",
    "        \n",
    "        Inputs:\n",
    "            tgt - Tensor of shape [L,B,1]\n",
    "            cache - Tensor of shape [I,L,B,Nh]\n",
    "            idx - index from which to start\n",
    "            \n",
    "        Outputs:\n",
    "            output - Tensor of shape [L+c,B,1]\n",
    "            new_cache - Tensor of shape [I,L+c,B,Nh]\n",
    "        \"\"\"\n",
    "        output = tgt\n",
    "        new_token_cache = []\n",
    "        #go through each layer and apply self attention only to the last input\n",
    "        for i, layer in enumerate(self.transformer.layers):\n",
    "            output = self.next_attn(output,layer,idx)\n",
    "            new_token_cache.append(output)\n",
    "            if cache is not None:\n",
    "                #layers after layer 1 need to use a cache of the previous layer's output on each input\n",
    "                output = torch.cat([cache[i], output], dim=0)\n",
    "\n",
    "        #update cache with new output\n",
    "        if cache is not None:\n",
    "            new_cache = torch.cat([cache, torch.stack(new_token_cache, dim=0)], dim=1)\n",
    "        else:\n",
    "            new_cache = torch.stack(new_token_cache, dim=0)\n",
    "\n",
    "        return output, new_cache\n",
    "    \n",
    "    def make_cache(self,tgt):\n",
    "        output = tgt\n",
    "        new_token_cache = []\n",
    "        #go through each layer and apply self attention only to the last input\n",
    "        for i, layer in enumerate(self.transformer.layers):\n",
    "            output = layer(output,src_mask=self.mask)#self.next_attn(output,layer,0)\n",
    "            new_token_cache.append(output)\n",
    "        #create cache with tensor\n",
    "        new_cache = torch.stack(new_token_cache, dim=0)\n",
    "        return output, new_cache\n",
    "    \n",
    "    def set_mask(self, L):\n",
    "        # take the log of a lower triangular matrix\n",
    "        self.L=L\n",
    "        self.mask = torch.log(torch.tril(torch.ones([L,L],device=self.device)))\n",
    "        self.pe.L=L\n",
    "        self.pe_t = self.pe.pe.transpose(1,0)\n",
    "    \n",
    "    \n",
    "    def sample(self,B,L):\n",
    "        \"\"\" Generates a set states\n",
    "        Inputs:\n",
    "            B (int)            - The number of states to generate in parallel\n",
    "            L (int)            - The length of generated vectors\n",
    "        Returns:\n",
    "            samples - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "        \"\"\"\n",
    "        #return (torch.rand([B,L,1],device=device)<0.5).to(torch.float32)\n",
    "        #Sample set will have shape [B,L,1]\n",
    "        #need one extra zero batch at the start for first pred hence input is [L+1,B,1] \n",
    "        #transformers don't do batch first so to save a bunch of transpose calls \n",
    "        input = torch.zeros([L+1,B,1],device=self.device)\n",
    "        #self.set_mask(L)\n",
    "        \n",
    "        cache=None\n",
    "        with torch.no_grad():\n",
    "          for idx in range(1,L+1):\n",
    "            #run the rnn on shape [B,1,1]   \n",
    "            #encode the input to the proper shape\n",
    "            encoded_input = input[:idx,:,:]+self.pe_t[:idx,:,:]\n",
    "                        \n",
    "            #Get transformer output\n",
    "            output,cache = self.next_with_cache(encoded_input,cache)\n",
    "            #if probs[i]=1 then there should be a 100% chance that sample[i]=1\n",
    "            #if probs[i]=0 then there should be a 0% chance that sample[i]=1\n",
    "            #stands that we generate a random uniform u and take int(u<probs) as our sample\n",
    "            probs=self.lin(output[-1,:,:])\n",
    "            sample = (torch.rand([B,1],device=device)<probs).to(torch.float32)\n",
    "            input[idx,:,:]=sample\n",
    "        #input's first entry is zero to get a predction for the first atom\n",
    "        #print(\".\",end=\"\")\n",
    "        return input.transpose(1,0)[:,1:,:]\n",
    "    \n",
    "    \n",
    "#functions below aren't really necessary anymore since there was no issue with masking (they serve to avoid using a mask)\n",
    "    def reset(self,B):\n",
    "        \"\"\"Setup for an autoregressive transformer\"\"\"\n",
    "        self._input = torch.zeros([self.L+1,B,1],device=self.device)\n",
    "        self._cache=None\n",
    "        self._i=0\n",
    "        return self.getnext(0)\n",
    "    def getnext(self,vect):\n",
    "        \"\"\"Get probability for the next output in an autoregressive transformer\"\"\"\n",
    "        self._input[self._i,:,:]=vect\n",
    "        self._i+=1\n",
    "        encoded_input = self._input[:self._i,:,:]+self.pe_t[:self._i,:,:]\n",
    "        output,self._cache = self.next_with_cache(encoded_input,self._cache)\n",
    "        probs=self.lin(output[-1,:,:])\n",
    "        return probs\n",
    "    def testsample(self,B,L,random=False):\n",
    "        \"\"\"Generate states with their probabilities in logscale\"\"\"\n",
    "        #set up variables\n",
    "        probs=self.reset(B).squeeze(0)\n",
    "        sprobs=torch.zeros([B],device=self.device)\n",
    "        samples = torch.zeros([B,L,1],device=self.device)\n",
    "        with torch.no_grad():\n",
    "          for idx in range(L):\n",
    "            #loop through L sequence elements and generate next in sequence based off of probabilities\n",
    "            rng = torch.rand([B,1],device=device)\n",
    "            if random:\n",
    "                sample = (rng<=0.5).to(torch.float32)\n",
    "            else:\n",
    "                sample = (rng<=probs).to(torch.float32)\n",
    "            samples[:,idx]=sample\n",
    "            sprobs+=torch.log(sample*probs+(1-sample)*(1-probs)).squeeze(1)\n",
    "            if idx!=L-1: probs = self.getnext(sample)\n",
    "        return samples,sprobs\n",
    "    \n",
    "    def testlabels(self,samples,B,L,D=1):\n",
    "        \"\"\"Get logscale probabilities of all states with one spin flipped at position j\"\"\"\n",
    "        with torch.no_grad():\n",
    "            print(\"|\",end=\"\")\n",
    "            B,L,one=samples.shape\n",
    "            logprobs=torch.zeros([B,L],device=self.device)\n",
    "            for k in range(L):\n",
    "                #loop cross L flipped states (batched)\n",
    "                probs=self.reset(B).squeeze(0)\n",
    "                sprobs = torch.zeros([B],device=self.device)\n",
    "                #loop across sequence\n",
    "                for idx in range(L):\n",
    "                    #kth state is flipped\n",
    "                    sample = samples[:,idx] if idx!=k else 1-samples[:,idx]\n",
    "                    sprobs+=torch.log(sample*probs+(1-sample)*(1-probs)).squeeze(1)\n",
    "                    if idx!=L-1: probs = self.getnext(sample)\n",
    "                logprobs[:,k]=sprobs\n",
    "        return samples,logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7403eb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L                             \t\t\t256\n",
      "Q                             \t\t\t1\n",
      "K                             \t\t\t256\n",
      "B                             \t\t\t256\n",
      "TOL                           \t\t\t0.15\n",
      "M                             \t\t\t0.9\n",
      "USEQUEUE                      \t\t\t0\n",
      "NLOOPS                        \t\t\t64\n",
      "hamiltonian                   \t\t\tRydberg\n",
      "steps                         \t\t\t12000\n",
      "dir                           \t\t\tTF\n",
      "Nh                            \t\t\t128\n",
      "lr                            \t\t\t0.0005\n",
      "kl                            \t\t\t0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "op=Opt()\n",
    "Lx=16\n",
    "op.L=Lx*Lx\n",
    "op.Nh=128\n",
    "op.lr=5e-4\n",
    "op.M=0.9\n",
    "op.Q=1\n",
    "op.K=256\n",
    "op.USEQUEUE=0\n",
    "op.kl=0.0\n",
    "#op.apply(sys.argv[1:])\n",
    "op.B=op.K*op.Q\n",
    "\n",
    "#op.steps=4000\n",
    "op.dir=\"TF\"\n",
    "#op.steps=100\n",
    "op.NLOOPS=64\n",
    "print(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f1cce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.system(\"python TF.py \"+op.cmd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "616bd3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'L=256 Q=1 K=256 B=256 TOL=0.15 M=0.9 USEQUEUE=0 NLOOPS=64 hamiltonian=Rydberg steps=12000 dir=TF Nh=128 lr=0.0005 kl=0.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.cmd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f9a845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsformer = FastTransformer(Lx,Lx,Nh=op.Nh,num_layers=2)\n",
    "sampleformer= FastTransformer(Lx,Lx,Nh=op.Nh,num_layers=2)\n",
    "beta1=0.9;beta2=0.999\n",
    "optimizer = torch.optim.Adam(\n",
    "trainsformer.parameters(), \n",
    "lr=op.lr, \n",
    "betas=(beta1,beta2)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2103fa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref=torch.load(\"E:\\SharedContent\\\\NN-QSR\\\\TF\\\\Rydberg\\\\256-NoQ-B=256-K=256-Nh=128-kl=0.00\\\\0\\\\T\")\n",
    "dbg = np.load(\"E:\\SharedContent\\\\NN-QSR\\\\TF\\\\Rydberg\\\\256-NoQ-B=256-K=256-Nh=128-kl=0.00\\\\0\\\\DEBUG.npy\")\n",
    "op.steps = 12000 - dbg.shape[0]\n",
    "momentum_update(0,trainsformer,ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11b25cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5210"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "801d1ef9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    B=32\n",
    "\n",
    "    s = trainsformer.sample(B,op.L)\n",
    "\n",
    "    probs = super(FastTransformer,trainsformer)._off_diag_labels(s,B,op.L,False,D=1)[1]\n",
    "\n",
    "    p2 = trainsformer._off_diag_labels(s,B,op.L,False,D=8)[1]\n",
    "\n",
    "    print(abs(probs-p2).mean().item(),torch.var_mean(probs)[0].item()**0.5)\n",
    "    print(abs(probs-p2).max())\n",
    "    plt.imshow(abs(probs-p2).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1119cc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1795713\n"
     ]
    }
   ],
   "source": [
    "print(sum (p.numel () for p in trainsformer.parameters ()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f415335d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training. . .\n",
      "Output folder path established\n",
      "-0.38052 256\n",
      "4,-0.38|2121,-0.38|4216,-0.38|6313,-0.38|8410,-0.38|10507,-0.38|12604,-0.38|14702,-0.38|16799,-0.38|18897,-0.38|20993,-0.38|21869.532111406326 5210\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if op.USEQUEUE:\n",
    "    queue_train(op,(trainsformer,sampleformer,optimizer))\n",
    "else:\n",
    "    print(\"Training. . .\")\n",
    "    reg_train(op,(trainsformer,optimizer))\n",
    "    #reg_train(op,(super(FastTransformer, trainsformer),optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d09b05f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-9e1622b385b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7516974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Batch size 32:\")\n",
    " \n",
    "t=time.time()\n",
    "for x in range(50):\n",
    "    super(FastTransformer, trainsformer).sample(32,op.L)\n",
    "print(\"old: \",time.time()-t)\n",
    "\n",
    "t=time.time()\n",
    "for x in range(50):\n",
    "    trainsformer.sample(32,op.L)\n",
    "print(\"new: \",time.time()-t)\n",
    "\n",
    "print(\"Batch size 320:\")\n",
    "\n",
    "t=time.time()\n",
    "for x in range(50):\n",
    "    super(FastTransformer, trainsformer).sample(320,op.L)\n",
    "print(\"old: \",time.time()-t)\n",
    "\n",
    "t=time.time()\n",
    "for x in range(50):\n",
    "    trainsformer.sample(320,op.L)\n",
    "print(\"new: \",time.time()-t)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4378195",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    #trainsformer = FastTransformer(Lx,Lx,Nh=op.Nh,num_layers=2)\n",
    "    torch.random.manual_seed(7)\n",
    "    s = trainsformer.sample(op.B,op.L)\n",
    "    print(s.shape)\n",
    "    plt.imshow(s[:,:,0].cpu())\n",
    "    plt.show()\n",
    "    torch.random.manual_seed(7)\n",
    "    s2 = super(FastTransformer, trainsformer).sample(op.B,op.L)\n",
    "    print(s2.shape)\n",
    "    plt.imshow(s2[:,:,0].cpu())\n",
    "    plt.show()\n",
    "    print(torch.sum(abs(s2-s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55984674",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train a gru\n",
    "op.dir=\"GRU\"\n",
    "trainrnn,optimizer=new_rnn_with_optim(\"GRU\",459,lr=op.lr)\n",
    "print(sum (p.numel () for p in trainrnn.parameters ()))\n",
    "reg_train(op,(trainrnn,optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b7dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lx=4\n",
    "op.L=Lx*Lx\n",
    "op.dir=\"GRU\"\n",
    "trainrnn,optimizer=new_rnn_with_optim(\"GRU\",320,lr=op.lr)\n",
    "print(sum (p.numel () for p in trainrnn.parameters ()))\n",
    "reg_train(op,(trainrnn,optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ea5f78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#op.steps=4000\n",
    "op.dir=\"TF\"\n",
    "\n",
    "\n",
    "if op.USEQUEUE:\n",
    "    queue_train(op,(trainsformer,sampleformer,optimizer))\n",
    "else:\n",
    "    print(\"Training. . .\")\n",
    "    reg_train(op,(trainsformer,optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d524bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(4*4).reshape([4,4,1]) + torch.ones([1,4,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec01ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = PE2D(40,6,6,torch.device('cpu')).pe\n",
    "print(pe.shape,pe.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2714445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pe[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3780fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros([1,2,3]).transpose(1,0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
