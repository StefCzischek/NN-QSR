{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a30b9c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from RNN_QSR import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02694a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PE2D(nn.Module):\n",
    "    def __init__(self, d_model, Lx,Ly,device,n_encode=None):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # create constant 'pe' matrix with values dependant on \n",
    "        # pos and i\n",
    "        pe = torch.zeros(Lx*Ly, d_model)\n",
    "        \n",
    "        if type(n_encode)==type(None):\n",
    "            n_encode=3*d_model//4\n",
    "        for pos in range(Lx*Ly):\n",
    "            x=pos//Ly\n",
    "            y=pos%Ly\n",
    "            # Only going to fill 3/4 of the matrix so the\n",
    "            # occupation values are preserved\n",
    "            for i in range(0, n_encode, 4):\n",
    "                \n",
    "                #x direction encoding\n",
    "                pe[pos, i] = \\\n",
    "                math.sin(x / (10000 ** ((2 * i)/n_encode)))\n",
    "                pe[pos, i + 1] = \\\n",
    "                math.cos(x / (10000 ** ((2 * (i + 1))/n_encode)))\n",
    "                #y direction encoding\n",
    "                pe[pos, i+2] = \\\n",
    "                math.sin(y / (10000 ** ((2 * i)/n_encode)))\n",
    "                pe[pos, i + 3] = \\\n",
    "                math.cos(y / (10000 ** ((2 * (i + 1))/n_encode)))\n",
    "                \n",
    "        self.pe = pe.unsqueeze(0).to(device)\n",
    "        self.L=Lx*Ly\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:,:self.L,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "406b661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlowTransformer(Sampler):\n",
    "    def __init__(self,Lx,Ly,device=device,Nh=128,decoder=False,dropout=0.0,num_layers=3, **kwargs):\n",
    "        super(SlowTransformer, self).__init__(device=device)\n",
    "        \n",
    "        self.pe = PE2D(Nh, Lx,Ly,device)\n",
    "        \n",
    "        if decoder:\n",
    "            #Decoder only transformer\n",
    "            self.decoder_layer = nn.TransformerDecoderLayer(d_model=Nh, nhead=8, dropout=dropout)\n",
    "            self.transformer = nn.TransformerDecoder(self.decoder_layer, num_layers=num_layers)\n",
    "        else:\n",
    "            #Encoder only transformer\n",
    "            self.encoder_layer = nn.TransformerEncoderLayer(d_model=Nh, nhead=8, dropout=dropout)\n",
    "            self.transformer = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)        \n",
    "        \n",
    "        self.lin = nn.Sequential(\n",
    "                nn.Linear(Nh,1),\n",
    "                #nn.ReLU(),\n",
    "                #nn.Linear(128,1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "        \n",
    "        self.set_mask(Lx*Ly)\n",
    "        self.to(device)\n",
    "        \n",
    "    def set_mask(self, L):\n",
    "        # take the log of a lower triangular matrix\n",
    "        self.L=L\n",
    "        self.mask = torch.log(torch.tril(torch.ones(L,L))).to(device)\n",
    "        self.pe.L=L\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input is shape [B,L,1]\n",
    "        # add positional encoding to get shape [B,L,Nh]\n",
    "        if input.shape[1]!=self.L:\n",
    "            self.set_mask(input.shape[1])\n",
    "        \n",
    "        input=self.pe(input).transpose(1,0)\n",
    "        output = self.transformer(input,self.mask)\n",
    "        output = self.lin(output.transpose(1,0))\n",
    "        return output\n",
    "    \n",
    "    \n",
    "    def logprobability(self,input):\n",
    "        \"\"\"Compute the logscale probability of a given state\n",
    "            Inputs:\n",
    "                input - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "            Returns:\n",
    "                logp - [B] size vector of logscale probability labels\n",
    "        \"\"\"\n",
    "        \n",
    "        #Input should have shape [B,L,1]\n",
    "        B,L,one=input.shape\n",
    "        \n",
    "        #first prediction is with the zero input vector\n",
    "        data=torch.zeros([B,L,one],device=self.device)\n",
    "        #data is the input vector shifted one to the right, with the very first entry set to zero instead of using pbc\n",
    "        data[:,1:,:]=input[:,:-1,:]\n",
    "        \n",
    "        #real is going to be a set of actual values\n",
    "        real=input\n",
    "        #and pred is going to be a set of probabilities\n",
    "        #if real[i]=1 than you multiply your conditional probability by pred[i]\n",
    "        #if real[i]=0 than you multiply by 1-pred[i]\n",
    "        \n",
    "        #probability predictions may be done WITH gradients\n",
    "        #with torch.no_grad():\n",
    "        \n",
    "        pred = self.forward(data)\n",
    "        ones = real*pred\n",
    "        zeros=(1-real)*(1-pred)\n",
    "        total = ones+zeros\n",
    "        #this is the sum you see in the cell above\n",
    "        #add 1e-10 to the prediction to avoid nans when total=0\n",
    "        logp=torch.sum(torch.log(total+1e-10),dim=1).squeeze(1)\n",
    "        return logp\n",
    "    def sample(self,B,L):\n",
    "        \"\"\" Generates a set states\n",
    "        Inputs:\n",
    "            B (int)            - The number of states to generate in parallel\n",
    "            L (int)            - The length of generated vectors\n",
    "        Returns:\n",
    "            samples - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "        \"\"\"\n",
    "        \n",
    "        #Sample set will have shape [B,L,1]\n",
    "        #need one extra zero batch at the start for first pred hence input is [N,L+1,1] \n",
    "        input = torch.zeros([B,L+1,1],device=self.device)\n",
    "        \n",
    "        self.set_mask(L)\n",
    "        #sampling can be done without gradients\n",
    "        with torch.no_grad():\n",
    "          for idx in range(1,L+1):\n",
    "            #run the rnn on shape [B,1,1]   \n",
    "            #encode the input to the proper shape\n",
    "            encoded_input = input[:,:idx,:]+self.pe.pe[:,:idx,:]\n",
    "                        \n",
    "            #Get transformer output\n",
    "            output = self.transformer(encoded_input.transpose(1,0),self.mask[:idx,:idx])\n",
    "            #if probs[i]=1 then there should be a 100% chance that sample[i]=1\n",
    "            #if probs[i]=0 then there should be a 0% chance that sample[i]=1\n",
    "            #stands that we generate a random uniform u and take int(u<probs) as our sample\n",
    "            probs=self.lin(output.transpose(1,0)[:,-1,:])\n",
    "            sample = (torch.rand([B,1],device=device)<probs).to(torch.float32)\n",
    "            input[:,idx,:]=sample\n",
    "        #input's first entry is zero to get a predction for the first atom\n",
    "        return input[:,1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f9a845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsformer = SlowTransformer(8,8,Nh=64,num_layers=2)\n",
    "sampleformer= SlowTransformer(8,8,Nh=64,num_layers=2)\n",
    "beta1=0.9;beta2=0.999\n",
    "optimizer = torch.optim.Adam(\n",
    "trainsformer.parameters(), \n",
    "lr=1e-3, \n",
    "betas=(beta1,beta2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32ea5f78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L                             \t\t\t64\n",
      "Q                             \t\t\t2\n",
      "K                             \t\t\t16\n",
      "B                             \t\t\t512\n",
      "TOL                           \t\t\t0.15\n",
      "M                             \t\t\t0.96875\n",
      "USEQUEUE                      \t\t\t0\n",
      "NLOOPS                        \t\t\t1\n",
      "hamiltonian                   \t\t\tRydberg\n",
      "steps                         \t\t\t12000\n",
      "dir                           \t\t\tTF\n",
      "\n",
      "Output folder path established\n",
      "-0.40522 64\n",
      "0,0.18|27,nan|53,nan|80,nan|106,nan|132,nan|158,nan|184,nan|"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-42503e38ebf0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mqueue_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainsformer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msampleformer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mreg_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Python Scripts\\ResearchF2022\\NN-QSR\\RNN_QSR.py\u001b[0m in \u001b[0;36mreg_train\u001b[1;34m(op, to)\u001b[0m\n\u001b[0;32m    706\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m         \u001b[1;31m#gather samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    709\u001b[0m         \u001b[0mfill_queue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m         \u001b[1;31m# get probability labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\ResearchF2022\\NN-QSR\\RNN_QSR.py\u001b[0m in \u001b[0;36mfill_queue\u001b[1;34m()\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfill_queue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m             \u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msump\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msqrtp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_with_labelsALT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnloops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNLOOPS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[0msamplequeue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\ResearchF2022\\NN-QSR\\RNN_QSR.py\u001b[0m in \u001b[0;36msample_with_labelsALT\u001b[1;34m(self, B, L, grad, nloops)\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[0msumsqrtp\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msize\u001b[0m \u001b[0mB\u001b[0m \u001b[0mvector\u001b[0m \u001b[0mof\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlogsqrtp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;31m'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \"\"\"\n\u001b[1;32m--> 260\u001b[1;33m         \u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_with_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnloops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m         \u001b[1;31m#get the average of our logprobabilities and divide by 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[0mlogsqrtp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\ResearchF2022\\NN-QSR\\RNN_QSR.py\u001b[0m in \u001b[0;36msample_with_labels\u001b[1;34m(self, B, L, grad, nloops)\u001b[0m\n\u001b[0;32m    225\u001b[0m                     \u001b[0mrelative\u001b[0m \u001b[0mto\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \"\"\"\n\u001b[1;32m--> 227\u001b[1;33m         \u001b[0msample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_off_diag_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnloops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\ResearchF2022\\NN-QSR\\RNN_QSR.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, B, L)\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[1;31m#stands that we generate a random uniform u and take int(u<probs) as our sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m             \u001b[0mprobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m             \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mprobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;31m#input's first entry is zero to get a predction for the first atom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "op=Opt()\n",
    "op.L=8*8\n",
    "op.Q=2\n",
    "op.USEQUEUE=0\n",
    "#op.apply(sys.argv[1:])\n",
    "#op.B=op.K*op.Q\n",
    "#op.steps=4000\n",
    "op.dir=\"TF\"\n",
    "print(op)\n",
    "\n",
    "if op.USEQUEUE:\n",
    "    queue_train(op,(trainsformer,sampleformer,optimizer))\n",
    "else:\n",
    "    reg_train(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d524bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(4*4).reshape([4,4,1]) + torch.ones([1,4,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec01ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = PE2D(40,6,6,torch.device('cpu')).pe\n",
    "print(pe.shape,pe.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2714445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pe[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3780fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros([1,2,3]).transpose(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc274ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
