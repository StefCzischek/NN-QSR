{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a30b9c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from RNN_QSR import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02694a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PE2D(nn.Module):\n",
    "    #TODO: Positional encoding is wrong because the spins are at index i+1 when we sample and get probabilities\n",
    "    def __init__(self, d_model, Lx,Ly,device,n_encode=None):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # create constant 'pe' matrix with values dependant on \n",
    "        # pos and i\n",
    "        pe = torch.zeros(Lx*Ly, d_model)\n",
    "        \n",
    "        if type(n_encode)==type(None):\n",
    "            n_encode=3*d_model//4\n",
    "        for pos in range(Lx*Ly):\n",
    "            x=pos//Ly\n",
    "            y=pos%Ly\n",
    "            # Only going to fill 3/4 of the matrix so the\n",
    "            # occupation values are preserved\n",
    "            for i in range(0, n_encode, 4):\n",
    "                \n",
    "                #x direction encoding\n",
    "                pe[pos, i] = \\\n",
    "                math.sin(x / (10000 ** ((2 * i)/n_encode)))\n",
    "                pe[pos, i + 1] = \\\n",
    "                math.cos(x / (10000 ** ((2 * (i + 1))/n_encode)))\n",
    "                #y direction encoding\n",
    "                pe[pos, i+2] = \\\n",
    "                math.sin(y / (10000 ** ((2 * i)/n_encode)))\n",
    "                pe[pos, i + 3] = \\\n",
    "                math.cos(y / (10000 ** ((2 * (i + 1))/n_encode)))\n",
    "                \n",
    "        self.pe = pe.unsqueeze(0).to(device)\n",
    "        self.L=Lx*Ly\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:,:self.L,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "406b661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlowTransformer(Sampler):\n",
    "    def __init__(self,Lx,Ly,device=device,Nh=128,decoder=False,dropout=0.0,num_layers=3, **kwargs):\n",
    "        super(SlowTransformer, self).__init__(device=device)\n",
    "        \n",
    "        self.pe = PE2D(Nh, Lx,Ly,device)\n",
    "        \n",
    "        if decoder:\n",
    "            #Decoder only transformer\n",
    "            self.decoder_layer = nn.TransformerDecoderLayer(d_model=Nh, nhead=8, dropout=dropout)\n",
    "            self.transformer = nn.TransformerDecoder(self.decoder_layer, num_layers=num_layers)\n",
    "        else:\n",
    "            #Encoder only transformer\n",
    "            #misinterperetation on encoder made it so this code does not work\n",
    "            self.encoder_layer = nn.TransformerEncoderLayer(d_model=Nh, nhead=8, dropout=dropout)\n",
    "            self.transformer = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)        \n",
    "        \n",
    "        self.lin = nn.Sequential(\n",
    "                nn.Linear(Nh,Nh),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(Nh,1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "        \n",
    "        self.set_mask(Lx*Ly)\n",
    "        self.to(device)\n",
    "        \n",
    "    def set_mask(self, L):\n",
    "        # take the log of a lower triangular matrix\n",
    "        self.L=L\n",
    "        self.mask = torch.log(torch.tril(torch.ones(L,L))).to(device)\n",
    "        self.pe.L=L\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input is shape [B,L,1]\n",
    "        # add positional encoding to get shape [B,L,Nh]\n",
    "        if input.shape[1]!=self.L:\n",
    "            self.set_mask(input.shape[1])\n",
    "        \n",
    "        input=self.pe(input).transpose(1,0)\n",
    "        output = self.transformer(input,self.mask)\n",
    "        output = self.lin(output.transpose(1,0))\n",
    "        return output\n",
    "    \n",
    "    \n",
    "    def logprobability(self,input):\n",
    "        \"\"\"Compute the logscale probability of a given state\n",
    "            Inputs:\n",
    "                input - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "            Returns:\n",
    "                logp - [B] size vector of logscale probability labels\n",
    "        \"\"\"\n",
    "        \n",
    "        #Input should have shape [B,L,1]\n",
    "        B,L,one=input.shape\n",
    "        \n",
    "        #first prediction is with the zero input vector\n",
    "        data=torch.zeros([B,L,one],device=self.device)\n",
    "        #data is the input vector shifted one to the right, with the very first entry set to zero instead of using pbc\n",
    "        data[:,1:,:]=input[:,:-1,:]\n",
    "        \n",
    "        #real is going to be a set of actual values\n",
    "        real=input\n",
    "        #and pred is going to be a set of probabilities\n",
    "        #if real[i]=1 than you multiply your conditional probability by pred[i]\n",
    "        #if real[i]=0 than you multiply by 1-pred[i]\n",
    "        \n",
    "        #probability predictions may be done WITH gradients\n",
    "        #with torch.no_grad():\n",
    "        \n",
    "        pred = self.forward(data)\n",
    "        ones = real*pred\n",
    "        zeros=(1-real)*(1-pred)\n",
    "        total = ones+zeros\n",
    "        #this is the sum you see in the cell above\n",
    "        #add 1e-10 to the prediction to avoid nans when total=0\n",
    "        logp=torch.sum(torch.log(total+1e-10),dim=1).squeeze(1)\n",
    "        return logp\n",
    "    def sample(self,B,L):\n",
    "        \"\"\" Generates a set states\n",
    "        Inputs:\n",
    "            B (int)            - The number of states to generate in parallel\n",
    "            L (int)            - The length of generated vectors\n",
    "        Returns:\n",
    "            samples - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "        \"\"\"\n",
    "        \n",
    "        #Sample set will have shape [B,L,1]\n",
    "        #need one extra zero batch at the start for first pred hence input is [N,L+1,1] \n",
    "        input = torch.zeros([B,L+1,1],device=self.device)\n",
    "        \n",
    "        #self.set_mask(L)\n",
    "        #sampling can be done without gradients\n",
    "        with torch.no_grad():\n",
    "          for idx in range(1,L+1):\n",
    "            #run the rnn on shape [B,1,1]   \n",
    "            #encode the input to the proper shape\n",
    "            encoded_input = input[:,:idx,:]+self.pe.pe[:,:idx,:]\n",
    "                        \n",
    "            #Get transformer output\n",
    "            output = self.transformer(encoded_input.transpose(1,0),self.mask[:idx,:idx])\n",
    "            #if probs[i]=1 then there should be a 100% chance that sample[i]=1\n",
    "            #if probs[i]=0 then there should be a 0% chance that sample[i]=1\n",
    "            #stands that we generate a random uniform u and take int(u<probs) as our sample\n",
    "            probs=self.lin(output.transpose(1,0)[:,-1,:])\n",
    "            sample = (torch.rand([B,1],device=device)<probs).to(torch.float32)\n",
    "            input[:,idx,:]=sample\n",
    "        #input's first entry is zero to get a predction for the first atom\n",
    "        return input[:,1:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaf620b",
   "metadata": {},
   "source": [
    "# Modification of Source here:\n",
    "[Docs](https://virtualgroup.cn/pytorch.org/docs/stable/_modules/torch/nn/modules/transformer.html#TransformerEncoderLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4602efb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastTransformer(SlowTransformer):\n",
    "    #TODO: Positional encoding is wrong because the spins are at index i+1 when we sample and get probabilities\n",
    "    def _off_diag_labels(self,sample,B,L,grad,D=1): #_off_diag_labels\n",
    "        \"\"\"label all of the flipped states  - set D as high as possible without it slowing down runtime\"\"\"\n",
    "        sflip = torch.zeros([B,L,L,1],device=self.device)\n",
    "        #collect all of the flipped states into one array\n",
    "        for j in range(L):\n",
    "            #get all of the states with one spin flipped\n",
    "            sflip[:,j] = sample*1.0\n",
    "            sflip[:,j,j] = 1-sflip[:,j,j]\n",
    "        #compute all of their logscale probabilities\n",
    "        with torch.no_grad():\n",
    "            #prepare sample to be used as cache\n",
    "            B,L,one=sample.shape\n",
    "            dsample=torch.zeros([B,L,one],device=self.device)\n",
    "            dsample[:,1:,:]=sample[:,:-1,:]\n",
    "\n",
    "            #add positional encoding and make the cache\n",
    "            out,cache=self.make_cache(self.pe(dsample).transpose(1,0))\n",
    "\n",
    "            probs=torch.zeros([B,L],device=self.device)\n",
    "\n",
    "            #expand cache to group L//D flipped states\n",
    "            cache=cache.unsqueeze(2)\n",
    "\n",
    "            #this line took like 1 hour to write I'm so sad\n",
    "            #the cache has to be shaped such that the batch parts line up\n",
    "            cache=cache.repeat(1,1,L//D,1,1).transpose(2,3).reshape(2,L,B*L//D,cache.shape[-1])\n",
    "\n",
    "            pred0 = self.lin(out.transpose(1,0))\n",
    "            ones = sample*pred0\n",
    "            zeros=(1-sample)*(1-pred0)\n",
    "            total0 = ones+zeros\n",
    "\n",
    "            for k in range(D):\n",
    "\n",
    "                N = k*L//D\n",
    "                #next couple of steps are crucial          \n",
    "                #get the samples from N to N+L//D\n",
    "                #Note: samples are the same as the original up to the Nth spin\n",
    "                real = sflip[:,N:(k+1)*L//D]\n",
    "                #flatten it out \n",
    "                tmp = real.reshape([B*L//D,L,1])\n",
    "                #set up next state predction\n",
    "                fsample=torch.zeros(tmp.shape,device=self.device)\n",
    "                fsample[:,1:,:]=tmp[:,:-1,:]\n",
    "                # put sequence before batch so you can use it with your transformer\n",
    "                tgt=self.pe(fsample).transpose(1,0)\n",
    "                #grab your transformer output\n",
    "                out,_=self.next_with_cache(tgt,cache[:,:N],N)\n",
    "\n",
    "                # self.lin actually does some repeated work but it's probably\n",
    "                # negligable compared to the time attention takes\n",
    "                output = self.lin(out[N:].transpose(1,0))\n",
    "                # reshape output separating batch from spin flip grouping\n",
    "                pred = output.view([B,L//D,L-N,1])\n",
    "                real=real[:,:,N:]\n",
    "                ones = real*pred\n",
    "                zeros=(1-real)*(1-pred)\n",
    "                total = ones+zeros\n",
    "                #sum across the sequence for probabilities\n",
    "                logp=torch.sum(torch.log(total+1e-10),dim=2).squeeze(2)\n",
    "                logp+=torch.sum(torch.log(total0[:,:N]+1e-10),dim=1)\n",
    "                probs[:,N:(k+1)*L//D]=logp\n",
    "                \n",
    "        return sample,probs\n",
    "    def next_attn(_,tgt,layer,i=-1):\n",
    "        \"\"\"Calculates self attention with tgt and the last elem of tgt\n",
    "        Inputs: \n",
    "            tgt - Tensor of shape [L+1,B,1]\n",
    "            layer - TransformerDecoderLayer\n",
    "            i - index of the first bit we want self-attention from\n",
    "        Outputs:\n",
    "            Tensor of shape [1,B,1]\n",
    "        \"\"\"\n",
    "        src = tgt[i:, :, :]\n",
    "        mask = None if i==-1 else _.mask[i:]\n",
    "        # self attention part\n",
    "        src2 = layer.self_attn(\n",
    "            src,#only do attention with the last elem of the sequence\n",
    "            tgt,\n",
    "            tgt,\n",
    "            attn_mask=mask,  # not needed because we only care about the last token\n",
    "            key_padding_mask=None,\n",
    "        )[0]\n",
    "        #straight from torch transformer encoder code\n",
    "        src = src + layer.dropout1(src2)\n",
    "        src = layer.norm1(src)\n",
    "        src2 = layer.linear2(layer.dropout(layer.activation(layer.linear1(src))))\n",
    "        src = src + layer.dropout2(src2)\n",
    "        src = layer.norm2(src)\n",
    "        return src\n",
    "    \n",
    "    def next_with_cache(self,tgt,cache=None,idx=-1):\n",
    "        \"\"\"Efficiently calculates the next output of a transformer given the input sequence and \n",
    "        cached intermediate layer encodings of the input sequence\n",
    "        \n",
    "        Inputs:\n",
    "            tgt - Tensor of shape [L,B,1]\n",
    "            cache - Tensor of shape ?\n",
    "            idx - index from which to start\n",
    "            \n",
    "        Outputs:\n",
    "            output - Tensor of shape [?,B,1]\n",
    "            new_cache - Tensor of shape ?\n",
    "        \"\"\"\n",
    "        output = tgt\n",
    "        new_token_cache = []\n",
    "        #go through each layer and apply self attention only to the last input\n",
    "        for i, layer in enumerate(self.transformer.layers):\n",
    "            output = self.next_attn(output,layer,idx)\n",
    "            new_token_cache.append(output)\n",
    "            if cache is not None:\n",
    "                #layers after layer 1 need to use a cache of the previous layer's output on each input\n",
    "                output = torch.cat([cache[i], output], dim=0)\n",
    "\n",
    "        #update cache with new output\n",
    "        if cache is not None:\n",
    "            new_cache = torch.cat([cache, torch.stack(new_token_cache, dim=0)], dim=1)\n",
    "        else:\n",
    "            new_cache = torch.stack(new_token_cache, dim=0)\n",
    "\n",
    "        return output, new_cache\n",
    "    \n",
    "    def make_cache(self,tgt):\n",
    "        output = tgt\n",
    "        new_token_cache = []\n",
    "        #go through each layer and apply self attention only to the last input\n",
    "        for i, layer in enumerate(self.transformer.layers):\n",
    "            output = layer(output,src_mask=self.mask)#self.next_attn(output,layer,0)\n",
    "            new_token_cache.append(output)\n",
    "        #create cache with tensor\n",
    "        new_cache = torch.stack(new_token_cache, dim=0)\n",
    "        return output, new_cache\n",
    "    \n",
    "    def set_mask(self, L):\n",
    "        # take the log of a lower triangular matrix\n",
    "        self.L=L\n",
    "        self.mask = torch.log(torch.tril(torch.ones(L,L))).to(device)\n",
    "        self.pe.L=L\n",
    "        self.pe_t = self.pe.pe.transpose(1,0)\n",
    "    \n",
    "    \n",
    "    def sample(self,B,L):\n",
    "        \"\"\" Generates a set states\n",
    "        Inputs:\n",
    "            B (int)            - The number of states to generate in parallel\n",
    "            L (int)            - The length of generated vectors\n",
    "        Returns:\n",
    "            samples - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "        \"\"\"\n",
    "        #return (torch.rand([B,L,1],device=device)<0.5).to(torch.float32)\n",
    "        #Sample set will have shape [B,L,1]\n",
    "        #need one extra zero batch at the start for first pred hence input is [L+1,B,1] \n",
    "        #transformers don't do batch first so to save a bunch of transpose calls \n",
    "        input = torch.zeros([L+1,B,1],device=self.device)\n",
    "        #self.set_mask(L)\n",
    "        \n",
    "        cache=None\n",
    "        with torch.no_grad():\n",
    "          for idx in range(1,L+1):\n",
    "            #run the rnn on shape [B,1,1]   \n",
    "            #encode the input to the proper shape\n",
    "            encoded_input = input[:idx,:,:]+self.pe_t[:idx,:,:]\n",
    "                        \n",
    "            #Get transformer output\n",
    "            output,cache = self.next_with_cache(encoded_input,cache)\n",
    "            #if probs[i]=1 then there should be a 100% chance that sample[i]=1\n",
    "            #if probs[i]=0 then there should be a 0% chance that sample[i]=1\n",
    "            #stands that we generate a random uniform u and take int(u<probs) as our sample\n",
    "            probs=self.lin(output[-1,:,:])\n",
    "            sample = (torch.rand([B,1],device=device)<probs).to(torch.float32)\n",
    "            input[idx,:,:]=sample\n",
    "        #input's first entry is zero to get a predction for the first atom\n",
    "        #print(\".\",end=\"\")\n",
    "        return input.transpose(1,0)[:,1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7403eb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L                             \t\t\t64\n",
      "Q                             \t\t\t1\n",
      "K                             \t\t\t32\n",
      "B                             \t\t\t32\n",
      "TOL                           \t\t\t0.15\n",
      "M                             \t\t\t0.96875\n",
      "USEQUEUE                      \t\t\t0\n",
      "NLOOPS                        \t\t\t1\n",
      "hamiltonian                   \t\t\tRydberg\n",
      "steps                         \t\t\t12000\n",
      "dir                           \t\t\tout\n",
      "Nh                            \t\t\t64\n",
      "lr                            \t\t\t0.0005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Settings\n",
    "op=Opt()\n",
    "Lx=8\n",
    "op.L=Lx*Lx\n",
    "op.Nh=64\n",
    "op.lr=5e-4\n",
    "op.Q=1\n",
    "op.K=32\n",
    "op.USEQUEUE=0\n",
    "#op.apply(sys.argv[1:])\n",
    "op.B=op.K*op.Q\n",
    "print(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f9a845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsformer = FastTransformer(Lx,Lx,Nh=op.Nh,num_layers=2)\n",
    "sampleformer= FastTransformer(Lx,Lx,Nh=op.Nh,num_layers=2)\n",
    "beta1=0.9;beta2=0.999\n",
    "optimizer = torch.optim.Adam(\n",
    "trainsformer.parameters(), \n",
    "lr=op.lr, \n",
    "betas=(beta1,beta2)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "801d1ef9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.186884224414825e-05 0.7202140575339988\n",
      "tensor(0.0005, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x221a829bb08>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "B=32\n",
    "\n",
    "s = trainsformer.sample(B,op.L)\n",
    "\n",
    "probs = super(FastTransformer,trainsformer)._off_diag_labels(s,B,op.L,False,D=1)[1]\n",
    "\n",
    "p2 = trainsformer._off_diag_labels(s,B,op.L,False,D=8)[1]\n",
    "\n",
    "print(abs(probs-p2).mean().item(),torch.var_mean(probs)[0].item()**0.5)\n",
    "print(abs(probs-p2).max())\n",
    "plt.imshow(abs(probs-p2).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1119cc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847681\n"
     ]
    }
   ],
   "source": [
    "print(sum (p.numel () for p in trainsformer.parameters ()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f415335d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training. . .\n",
      "Output folder path established\n",
      "-0.40522 64\n",
      "0,2.22|78,-0.31|155,-0.32|232,-0.35|309,-0.34|386,-0.35|464,-0.36|541,-0.36|618,-0.38|696,-0.41|779,-0.41|855,-0.41|931,-0.41|1008,-0.41|1085,-0.42|1162,-0.41|1239,-0.42|1315,-0.41|1392,-0.41|1469,-0.41|1544,-0.41|1620,-0.41|1695,-0.41|1772,-0.41|1849.4891369342804 12000\n"
     ]
    }
   ],
   "source": [
    "#op.steps=4000\n",
    "op.dir=\"TEST\"\n",
    "#op.steps=100\n",
    "op.NLOOPS=16\n",
    "if op.USEQUEUE:\n",
    "    queue_train(op,(trainsformer,sampleformer,optimizer))\n",
    "else:\n",
    "    print(\"Training. . .\")\n",
    "    reg_train(op,(trainsformer,optimizer))\n",
    "    #reg_train(op,(super(FastTransformer, trainsformer),optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7516974f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size 32:\n",
      "old:  3.984227418899536\n",
      "new:  3.6998283863067627\n",
      "Batch size 320:\n",
      "old:  25.44533944129944\n",
      "new:  4.284188985824585\n"
     ]
    }
   ],
   "source": [
    "print(\"Batch size 32:\")\n",
    "\n",
    "t=time.time()\n",
    "for x in range(50):\n",
    "    super(FastTransformer, trainsformer).sample(32,op.L)\n",
    "print(\"old: \",time.time()-t)\n",
    "\n",
    "t=time.time()\n",
    "for x in range(50):\n",
    "    trainsformer.sample(32,op.L)\n",
    "print(\"new: \",time.time()-t)\n",
    "\n",
    "print(\"Batch size 320:\")\n",
    "\n",
    "t=time.time()\n",
    "for x in range(50):\n",
    "    super(FastTransformer, trainsformer).sample(320,op.L)\n",
    "print(\"old: \",time.time()-t)\n",
    "\n",
    "t=time.time()\n",
    "for x in range(50):\n",
    "    trainsformer.sample(320,op.L)\n",
    "print(\"new: \",time.time()-t)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4378195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 1])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 1])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    #trainsformer = FastTransformer(Lx,Lx,Nh=op.Nh,num_layers=2)\n",
    "    torch.random.manual_seed(7)\n",
    "    s = trainsformer.sample(op.B,op.L)\n",
    "    print(s.shape)\n",
    "    plt.imshow(s[:,:,0].cpu())\n",
    "    plt.show()\n",
    "    torch.random.manual_seed(7)\n",
    "    s2 = super(FastTransformer, trainsformer).sample(op.B,op.L)\n",
    "    print(s2.shape)\n",
    "    plt.imshow(s2[:,:,0].cpu())\n",
    "    plt.show()\n",
    "    print(torch.sum(abs(s2-s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55984674",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847774\n",
      "Output folder path established\n",
      "-0.40522 64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-7fdee4bb667f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrainrnn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_rnn_with_optim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"GRU\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m459\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrainrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mreg_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainrnn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Python Scripts\\ResearchF2022\\NN-QSR\\RNN_QSR.py\u001b[0m in \u001b[0;36mreg_train\u001b[1;34m(op, to)\u001b[0m\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m         \u001b[1;31m#gather samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         \u001b[0mfill_queue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m         \u001b[1;31m# get probability labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m         \u001b[0mlogp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogprobability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamplequeue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\ResearchF2022\\NN-QSR\\RNN_QSR.py\u001b[0m in \u001b[0;36mfill_queue\u001b[1;34m()\u001b[0m\n\u001b[0;32m    698\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfill_queue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 700\u001b[1;33m             \u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msump\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msqrtp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_with_labelsALT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnloops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNLOOPS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    701\u001b[0m             \u001b[0msamplequeue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m             \u001b[0msump_queue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msump\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\ResearchF2022\\NN-QSR\\RNN_QSR.py\u001b[0m in \u001b[0;36msample_with_labelsALT\u001b[1;34m(self, B, L, grad, nloops)\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[0msumsqrtp\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msize\u001b[0m \u001b[0mB\u001b[0m \u001b[0mvector\u001b[0m \u001b[0mof\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlogsqrtp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;31m'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \"\"\"\n\u001b[1;32m--> 260\u001b[1;33m         \u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_with_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnloops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m         \u001b[1;31m#get the average of our logprobabilities and divide by 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[0mlogsqrtp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\ResearchF2022\\NN-QSR\\RNN_QSR.py\u001b[0m in \u001b[0;36msample_with_labels\u001b[1;34m(self, B, L, grad, nloops)\u001b[0m\n\u001b[0;32m    225\u001b[0m                     \u001b[0mrelative\u001b[0m \u001b[0mto\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \"\"\"\n\u001b[1;32m--> 227\u001b[1;33m         \u001b[0msample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_off_diag_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnloops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\ResearchF2022\\NN-QSR\\RNN_QSR.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, B, L)\u001b[0m\n\u001b[0;32m    372\u001b[0m             \u001b[1;31m#run the rnn on shape [B,1,1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m             \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m             \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m             \u001b[1;31m#if probs[i]=1 then there should be a 100% chance that sample[i]=1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    848\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 850\u001b[1;33m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    851\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train a gru\n",
    "op.dir=\"GRU\"\n",
    "trainrnn,optimizer=new_rnn_with_optim(\"GRU\",459,lr=op.lr)\n",
    "print(sum (p.numel () for p in trainrnn.parameters ()))\n",
    "reg_train(op,(trainrnn,optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5b7dcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413121\n",
      "Output folder path established\n",
      "-0.45776822 16\n",
      "0,2.01|5,-0.38|10,-0.42|15,-0.44|20,-0.45|25,-0.45|31,-0.45|36,-0.45|41,-0.46|46,-0.45|51,-0.46|56,-0.45|61,-0.45|66,-0.46|71,-0.46|76,-0.46|82,-0.46|87,-0.44|92,-0.45|97,-0.46|102,-0.46|107,-0.45|112,-0.45|117,-0.46|122.32494974136353 12000\n"
     ]
    }
   ],
   "source": [
    "Lx=4\n",
    "op.L=Lx*Lx\n",
    "op.dir=\"GRU\"\n",
    "trainrnn,optimizer=new_rnn_with_optim(\"GRU\",320,lr=op.lr)\n",
    "print(sum (p.numel () for p in trainrnn.parameters ()))\n",
    "reg_train(op,(trainrnn,optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32ea5f78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training. . .\n",
      "Output folder path established\n",
      "-0.40522 64\n",
      "0,2.38|133,-0.31|267,-0.30|400,-0.35|536,-0.37|670,-0.40|804,-0.41|938,-0.41|1072,-0.41|1206,-0.40|1340,-0.41|1474,-0.41|1609,-0.41|1743,-0.41|1877,-0.41|2011,-0.41|2146,-0.41|2285,-0.42|2426,-0.41|2560,-0.40|2695,-0.41|2829,-0.41|2963,-0.41|3097,-0.41|3231.5833308696747 12000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#op.steps=4000\n",
    "op.dir=\"TF\"\n",
    "\n",
    "\n",
    "if op.USEQUEUE:\n",
    "    queue_train(op,(trainsformer,sampleformer,optimizer))\n",
    "else:\n",
    "    print(\"Training. . .\")\n",
    "    reg_train(op,(trainsformer,optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d524bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  1.,  1.,  1.],\n",
       "         [ 2.,  2.,  2.,  2.],\n",
       "         [ 3.,  3.,  3.,  3.],\n",
       "         [ 4.,  4.,  4.,  4.]],\n",
       "\n",
       "        [[ 5.,  5.,  5.,  5.],\n",
       "         [ 6.,  6.,  6.,  6.],\n",
       "         [ 7.,  7.,  7.,  7.],\n",
       "         [ 8.,  8.,  8.,  8.]],\n",
       "\n",
       "        [[ 9.,  9.,  9.,  9.],\n",
       "         [10., 10., 10., 10.],\n",
       "         [11., 11., 11., 11.],\n",
       "         [12., 12., 12., 12.]],\n",
       "\n",
       "        [[13., 13., 13., 13.],\n",
       "         [14., 14., 14., 14.],\n",
       "         [15., 15., 15., 15.],\n",
       "         [16., 16., 16., 16.]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(4*4).reshape([4,4,1]) + torch.ones([1,4,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ec01ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 36, 40]) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "pe = PE2D(40,6,6,torch.device('cpu')).pe\n",
    "print(pe.shape,pe.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2714445c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ff48262d88>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pe[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3780fac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros([1,2,3]).transpose(1,0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
