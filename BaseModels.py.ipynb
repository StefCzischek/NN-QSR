{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adf7b69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 _CudaDeviceProperties(name='NVIDIA GeForce RTX 3080 Ti', major=8, minor=6, total_memory=12287MB, multi_processor_count=80)\n"
     ]
    }
   ],
   "source": [
    "from RNN_QSR import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa56499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastMaskedTransformerEncoder(nn.Module):#(torch.jit.ScriptModule):\n",
    "    \"\"\"\n",
    "    Base class for a fast, masked transformer\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,Nh=128,dropout=0.0,num_layers=2,nhead=8,device=device):\n",
    "        super(FastMaskedTransformerEncoder, self).__init__()\n",
    "        #print(nhead)\n",
    "        #Encoder only transformer\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=Nh, nhead=nhead, dropout=dropout)\n",
    "        self.transformer = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)        \n",
    "        self.device=device\n",
    "    def set_mask(self, L):\n",
    "        # type: (int)\n",
    "        \"\"\"\n",
    "        Set the transformer mask for a sequence of length L\n",
    "        Inputs: \n",
    "            L (int) - the desired sequence length\n",
    "        \"\"\"\n",
    "        # take the log of a lower triangular matrix\n",
    "        self.mask = torch.log(torch.tril(torch.ones([L,L],device=self.device)))        \n",
    "        \n",
    "    def forward(self, input):\n",
    "        # type: (Tensor)->Tensor\n",
    "        \"\"\"Run the transformer on a sequence of length L\n",
    "            Inputs:\n",
    "                input -  Tensor of shape [L,B,Nh]\n",
    "            Outputs:    \n",
    "                Tensor of shape [L,B,Nh]\n",
    "        \"\"\"\n",
    "        return self.transformer(input,self.mask)\n",
    "    \n",
    "    def next_with_cache(self,tgt,cache=None,idx=-1):\n",
    "        # type: (Tensor,Optional[Tensor],int) -> Tuple[Tensor,Tensor]\n",
    "        \"\"\"Efficiently calculates the next output of a transformer given the input sequence and \n",
    "        cached intermediate layer encodings of the input sequence\n",
    "        \n",
    "        Inputs:\n",
    "            tgt - Tensor of shape [L,B,Nh]\n",
    "            cache - Tensor of shape ?\n",
    "            idx - index from which to start\n",
    "            \n",
    "        Outputs:\n",
    "            output - Tensor of shape [?,B,Nh]\n",
    "            new_cache - Tensor of shape ?\n",
    "        \"\"\"\n",
    "        #HMMM\n",
    "        output = tgt\n",
    "        new_token_cache = []\n",
    "        #go through each layer and apply self attention only to the last input\n",
    "        for i,layer in enumerate(self.transformer.layers):\n",
    "            \n",
    "            tgt=output\n",
    "            #have to merge the functions into one\n",
    "            src = tgt[idx:, :, :]\n",
    "            mask = None if idx==-1 else self.mask[idx:]\n",
    "\n",
    "            # self attention part\n",
    "            src2 = layer.self_attn(\n",
    "                src,#only do attention with the last elem of the sequence\n",
    "                tgt,\n",
    "                tgt,\n",
    "                attn_mask=mask,  \n",
    "                key_padding_mask=None,\n",
    "            )[0]\n",
    "            #straight from torch transformer encoder code\n",
    "            src = src + layer.dropout1(src2)\n",
    "            src = layer.norm1(src)\n",
    "            src2 = layer.linear2(layer.dropout(layer.activation(layer.linear1(src))))\n",
    "            src = src + layer.dropout2(src2)\n",
    "            src = layer.norm2(src)\n",
    "            #return src\n",
    "            \n",
    "            output = src#self.next_attn(output,layer,idx)\n",
    "            new_token_cache.append(output)\n",
    "            if cache is not None:\n",
    "                #layers after layer 1 need to use a cache of the previous layer's output on each input\n",
    "                output = torch.cat([cache[i], output], dim=0)\n",
    "\n",
    "        #update cache with new output\n",
    "        if cache is not None:\n",
    "            new_cache = torch.cat([cache, torch.stack(new_token_cache, dim=0)], dim=1)\n",
    "        else:\n",
    "            new_cache = torch.stack(new_token_cache, dim=0)\n",
    "\n",
    "        return output, new_cache\n",
    "    \n",
    "    def make_cache(self,tgt):\n",
    "        # type: (Tensor) -> Tuple[Tensor,Tensor]\n",
    "        \"\"\"\n",
    "        Equivalent to forward, but the intermediate outputs are also returned\n",
    "        Inputs:\n",
    "            tgt - Tensor of shape [L,B,Nh]\n",
    "        Outputs:\n",
    "            output - Tensor of shape [L,B,Nh]\n",
    "            new_cache - Tensor of shape [?,L,B,Nh]\n",
    "        \"\"\"\n",
    "        output = tgt\n",
    "        new_token_cache = []\n",
    "        #go through each layer and apply self attention only to the last input\n",
    "        for i, layer in enumerate(self.transformer.layers):\n",
    "            output = layer(output,src_mask=self.mask)#self.next_attn(output,layer,0)\n",
    "            new_token_cache.append(output)\n",
    "        #create cache with tensor\n",
    "        new_cache = torch.stack(new_token_cache, dim=0)\n",
    "        return output, new_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bc686f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PE2D(nn.Module):\n",
    "    \"\"\"Sequence-First 2D Positional Encoder\"\"\"\n",
    "    #TODO: Positional encoding is wrong because the spins are at index i+1 when we sample and get probabilities\n",
    "    def __init__(self, d_model, Lx,Ly,device,n_encode=None):\n",
    "        \n",
    "        super().__init__()\n",
    "        assert (d_model%4==0)\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # create constant 'pe' matrix with values dependant on \n",
    "        # pos and i\n",
    "        pe = torch.zeros(Lx*Ly, d_model)\n",
    "        \n",
    "        if type(n_encode)==type(None):\n",
    "            n_encode=3*d_model//4\n",
    "        for pos in range(Lx*Ly):\n",
    "            x=pos//Ly\n",
    "            y=pos%Ly\n",
    "            # Only going to fill 3/4 of the matrix so the\n",
    "            # occupation values are preserved\n",
    "            for i in range(0, n_encode, 4):\n",
    "                \n",
    "                #x direction encoding\n",
    "                pe[pos, i] =                 math.sin(x / (10000 ** ((2 * i)/n_encode)))\n",
    "                pe[pos, i + 1] =                 math.cos(x / (10000 ** ((2 * (i + 1))/n_encode)))\n",
    "                #y direction encoding\n",
    "                pe[pos, i+2] =                 math.sin(y / (10000 ** ((2 * i)/n_encode)))\n",
    "                pe[pos, i + 3] =                 math.cos(y / (10000 ** ((2 * (i + 1))/n_encode)))\n",
    "                \n",
    "        self.pe = pe.unsqueeze(1).to(device)\n",
    "        self.L=Lx*Ly\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Adds a 2D positional encoding of size d_model to x\n",
    "        Inputs:\n",
    "            Tensor of shape [L,B,?]\n",
    "        Outputs:\n",
    "            Tensor of shape [L,B,d_model]\n",
    "        \"\"\"\n",
    "        if self.d_model%x.shape[-1]!=0:\n",
    "            return x.repeat(1,1,self.d_model//x.shape[-1]+1)[:,:,:self.d_model] + self.pe[:x.shape[0]]\n",
    "        return x.repeat(1,1,self.d_model//x.shape[-1]) + self.pe[:x.shape[0]]\n",
    "    \n",
    "class PE1D(nn.Module):\n",
    "    \"\"\"Sequence-First 1D Positional Encoder\"\"\"\n",
    "    def __init__(self, d_model, L,device,n_encode=None):\n",
    "        super().__init__()\n",
    "        assert (d_model%4==0)\n",
    "        self.d_model = d_model\n",
    "        # create constant 'pe' matrix with values dependent on \n",
    "        # pos and i\n",
    "        pe = torch.zeros(L, d_model)\n",
    "        if type(n_encode)==type(None):\n",
    "            n_encode=3*d_model//4\n",
    "        for pos in range(L):\n",
    "            # Only going to fill 3/4 of the matrix so the\n",
    "            # occupation values are preserved\n",
    "            for i in range(0, n_encode, 2):\n",
    "                #position encoding\n",
    "                pe[pos, i] =                 math.sin(pos / (10000 ** ((2 * i)/n_encode)))\n",
    "                pe[pos, i + 1] =             math.cos(pos / (10000 ** ((2 * (i + 1))/n_encode)))\n",
    "        self.pe = pe.unsqueeze(1).to(device)\n",
    "        self.L=L\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Adds a 1D positional encoding of size d_model to x\n",
    "        Inputs:\n",
    "            Tensor of shape [L,B,?]\n",
    "        Outputs:\n",
    "            Tensor of shape [L,B,d_model]\n",
    "        \"\"\"\n",
    "        if self.d_model%x.shape[-1]!=0:\n",
    "            return x.repeat(1,1,self.d_model//x.shape[-1]+1)[:,:,:self.d_model] + self.pe[:x.shape[0]]\n",
    "        return x.repeat(1,1,self.d_model//x.shape[-1]) + self.pe[:x.shape[0]]\n",
    "\n",
    "def pe2Dtest(Lx,Ly):\n",
    "    pe = torch.zeros(Lx*Ly, 2)\n",
    "    for pos in range(Lx*Ly):\n",
    "        x=pos//Ly\n",
    "        y=pos%Ly\n",
    "        # Only going to fill 3/4 of the matrix so the\n",
    "        # occupation values are preserved\n",
    "        #x direction encoding\n",
    "        pe[pos, 0] =                 x\n",
    "        #y direction encoding\n",
    "        pe[pos, 1] =                 y\n",
    "    return pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10c68639",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patch2D(nn.Module):\n",
    "    def __init__(self,n,Lx):\n",
    "        super().__init__()\n",
    "        self.n=n\n",
    "        self.Lx=Lx\n",
    "    def forward(self,x):\n",
    "        # type: (Tensor) -> Tensor\n",
    "        n,Lx=self.n,self.Lx\n",
    "        \"\"\"Unflatten a tensor back to 2D, break it into nxn chunks, then flatten the sequence and the chunks\n",
    "            Input:\n",
    "                Tensor of shape [B,L]\n",
    "            Output:\n",
    "                Tensor of shape [B,L//n^2,n^2]\n",
    "        \"\"\"\n",
    "        #make the input 2D then break it into 2x2 chunks \n",
    "        #afterwards reshape the 2x2 chunks to vectors of size 4 and flatten the 2d bit\n",
    "        return x.view([x.shape[0],Lx,Lx]).unfold(-2,n,n).unfold(-2,n,n).reshape([x.shape[0],int(Lx*Lx//n**2),int(n**2)])\n",
    "\n",
    "    def reverse(self,x):\n",
    "        # type: (Tensor) -> Tensor\n",
    "        \"\"\"Inverse function of forward\n",
    "            Input:\n",
    "                Tensor of shape [B,L//n^2,n^2]\n",
    "            Output:\n",
    "                Tensor of shape [B,L]\n",
    "        \"\"\"\n",
    "        n,Lx=self.n,self.Lx\n",
    "        # original sequence order can be retrieved by chunking twice more\n",
    "        #in the x-direction you should have chunks of size 2, but in y it should\n",
    "        #be chunks of size Ly//2\n",
    "        return x.unfold(-2,Lx//n,Lx//n).unfold(-2,n,n).reshape([x.shape[0],Lx*Lx])\n",
    "    \n",
    "class Patch1D(nn.Module):\n",
    "    def __init__(self,n,L):\n",
    "        super().__init__()\n",
    "        self.n=n\n",
    "        self.L = L\n",
    "    def forward(self,x):\n",
    "        # type: (Tensor) -> Tensor\n",
    "        \"\"\"Break a tensor into chunks, essentially a wrapper of reshape\n",
    "            Input:\n",
    "                Tensor of shape [B,L]\n",
    "            Output:\n",
    "                Tensor of shape [B,L/n,n]\n",
    "        \"\"\"\n",
    "        #make the input 2D then break it into 2x2 chunks \n",
    "        #afterwards reshape the 2x2 chunks to vectors of size 4 and flatten the 2d bit\n",
    "        return x.reshape([x.shape[0],self.L//self.n,self.n])\n",
    "\n",
    "    def reverse(self,x):\n",
    "        # type: (Tensor) -> Tensor\n",
    "        \"\"\"Inverse function of forward\n",
    "            Input:\n",
    "                Tensor of shape [B,L/n,n]\n",
    "            Output:\n",
    "                Tensor of shape [B,L]\n",
    "        \"\"\"\n",
    "        # original sequence order can be retrieved by chunking twice more\n",
    "        #in the x-direction you should have chunks of size 2, but in y it should\n",
    "        #be chunks of size Ly//2\n",
    "        return x.reshape([x.shape[0],self.L])\n",
    "    \n",
    "    \n",
    "@torch.jit.script\n",
    "def patch2onehot(patch):\n",
    "    #moving the last dimension to the front\n",
    "    patch=patch.unsqueeze(0).transpose(-1,0).squeeze(-1)\n",
    "    out=torch.zeros(patch.shape[1:],device=patch.device)\n",
    "    for i in range(4):\n",
    "        out+=patch[i]<<i\n",
    "    return nn.functional.one_hot(out.to(torch.int64), num_classes=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f3bc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(36).unsqueeze(0)\n",
    "\n",
    "patch2d = Patch2D(3,6)\n",
    "\n",
    "patch1d = Patch1D(3,36)\n",
    "\n",
    "y2 = patch2d(x)\n",
    "\n",
    "y1 = patch1d(x)\n",
    "\n",
    "print(x.view(6,6))\n",
    "\n",
    "print(y2)\n",
    "print(patch2d.reverse(y2).view(6,6))\n",
    "print(y1)\n",
    "print(patch1d.reverse(y1).view(6,6))\n",
    "\n",
    "pe2Dtest(6,6//3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aa590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TF(Sampler):\n",
    "    \"\"\"Same architecture as SlowTransformer (weights can be shared) but with improvements to sampling and labelling which\n",
    "    can give a 2x performance boost\"\"\"\n",
    "    \n",
    "    def __init__(self,Lx,Ly,device=device,Nh=128,dropout=0.0,num_layers=2,nhead=8, **kwargs):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            Lx,Ly (int) -- Sequence dimensions\n",
    "            Nh (int) -- size of the input vector at each sequence element (same as d_model)\n",
    "            decoder (bool) -- whether to use a TF decoder or encoder. Using a decoder isn't currently implemented\n",
    "        \"\"\"\n",
    "        super(TF, self).__init__(device=device)\n",
    "        \n",
    "        self.pe = PE2D(Nh, Lx,Ly,device)\n",
    "        \n",
    "        self.transformer = FastMaskedTransformerEncoder(Nh=Nh,dropout=dropout,num_layers=num_layers,nhead=nhead)        \n",
    "        \n",
    "        self.lin = nn.Sequential(\n",
    "                nn.Linear(Nh,Nh),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(Nh,1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "        \n",
    "        self.set_mask(Lx*Ly)\n",
    "        self.to(device)\n",
    "        \n",
    "    def set_mask(self, L):\n",
    "        # type: (int)\n",
    "        \"\"\"Initialize the self-attention mask\"\"\"\n",
    "        # take the log of a lower triangular matrix\n",
    "        self.L=L\n",
    "        self.transformer.set_mask(L)\n",
    "        self.pe.L=L\n",
    "\n",
    "    def forward(self, input):\n",
    "        \n",
    "        # input is shape [B,L,1]\n",
    "        # add positional encoding to get shape [B,L,Nh]\n",
    "        if input.shape[1]!=self.L:\n",
    "            self.set_mask(input.shape[1])\n",
    "        \n",
    "        input=self.pe(input.transpose(1,0))\n",
    "        output = self.transformer(input)\n",
    "        output = self.lin(output.transpose(1,0))\n",
    "        return output\n",
    "    \n",
    "    \n",
    "    def logprobability(self,input):\n",
    "        \"\"\"Compute the logscale probability of a given state\n",
    "            Inputs:\n",
    "                input - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "            Returns:\n",
    "                logp - [B] size vector of logscale probability labels\n",
    "        \"\"\"\n",
    "        \n",
    "        #Input should have shape [B,L,1]\n",
    "        B,L,one=input.shape\n",
    "        \n",
    "        #first prediction is with the zero input vector\n",
    "        data=torch.zeros([B,L,one],device=self.device)\n",
    "        #data is the input vector shifted one to the right, with the very first entry set to zero instead of using pbc\n",
    "        data[:,1:,:]=input[:,:-1,:]\n",
    "        \n",
    "        #real is going to be a set of actual values\n",
    "        real=input\n",
    "        #and pred is going to be a set of probabilities\n",
    "        #if real[i]=1 than you multiply your conditional probability by pred[i]\n",
    "        #if real[i]=0 than you multiply by 1-pred[i]\n",
    "        pred = self.forward(data)\n",
    "        ones = real*pred\n",
    "        zeros=(1-real)*(1-pred)\n",
    "        total = ones+zeros\n",
    "        #this is the sum you see in the cell above\n",
    "        #add 1e-10 to the prediction to avoid nans when total=0\n",
    "        logp=torch.sum(torch.log(total+1e-10),dim=1).squeeze(1)\n",
    "        return logp\n",
    "    def _off_diag_labels(self,sample,B,L,grad,D=1):\n",
    "        \"\"\"label all of the flipped states  - set D as high as possible without it slowing down runtime\n",
    "        Parameters:\n",
    "            sample - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "            B,L (int) - batch size and sequence length\n",
    "            D (int) - Number of partitions sequence-wise. We must have L%D==0 (D divides L)\n",
    "            \n",
    "        Outputs:\n",
    "            \n",
    "            sample - same as input\n",
    "            probs - [B,L] matrix of probabilities of states with the jth excitation flipped\n",
    "        \"\"\"\n",
    "        sflip = torch.zeros([B,L,L,1],device=self.device)\n",
    "        #collect all of the flipped states into one array\n",
    "        for j in range(L):\n",
    "            #get all of the states with one spin flipped\n",
    "            sflip[:,j] = sample*1.0\n",
    "            sflip[:,j,j] = 1-sflip[:,j,j]\n",
    "        #compute all of their logscale probabilities\n",
    "        with torch.no_grad():\n",
    "            #prepare sample to be used as cache\n",
    "            B,L,one=sample.shape\n",
    "            dsample=torch.zeros([B,L,one],device=self.device)\n",
    "            dsample[:,1:,:]=sample[:,:-1,:]\n",
    "\n",
    "            #add positional encoding and make the cache\n",
    "            out,cache=self.transformer.make_cache(self.pe(dsample.transpose(1,0)))\n",
    "\n",
    "            probs=torch.zeros([B,L],device=self.device)\n",
    "            #expand cache to group L//D flipped states\n",
    "            cache=cache.unsqueeze(2)\n",
    "\n",
    "            #this line took like 1 hour to write I'm so sad\n",
    "            #the cache has to be shaped such that the batch parts line up\n",
    "            cache=cache.repeat(1,1,L//D,1,1).transpose(2,3).reshape(cache.shape[0],L,B*L//D,cache.shape[-1])\n",
    "\n",
    "            pred0 = self.lin(out.transpose(1,0))\n",
    "            ones = sample*pred0\n",
    "            zeros=(1-sample)*(1-pred0)\n",
    "            total0 = ones+zeros\n",
    "\n",
    "            for k in range(D):\n",
    "\n",
    "                N = k*L//D\n",
    "                #next couple of steps are crucial          \n",
    "                #get the samples from N to N+L//D\n",
    "                #Note: samples are the same as the original up to the Nth spin\n",
    "                real = sflip[:,N:(k+1)*L//D]\n",
    "                #flatten it out \n",
    "                tmp = real.reshape([B*L//D,L,1])\n",
    "                #set up next state predction\n",
    "                fsample=torch.zeros(tmp.shape,device=self.device)\n",
    "                fsample[:,1:,:]=tmp[:,:-1,:]\n",
    "                # put sequence before batch so you can use it with your transformer\n",
    "                tgt=self.pe(fsample.transpose(1,0))\n",
    "                #grab your transformer output\n",
    "                out,_=self.transformer.next_with_cache(tgt,cache[:,:N],N)\n",
    "\n",
    "                # self.lin actually does some repeated work but it's probably\n",
    "                # negligable compared to the time attention takes\n",
    "                output = self.lin(out[N:].transpose(1,0))\n",
    "                # reshape output separating batch from spin flip grouping\n",
    "                pred = output.view([B,L//D,L-N,1])\n",
    "                real=real[:,:,N:]\n",
    "                ones = real*pred\n",
    "                zeros=(1-real)*(1-pred)\n",
    "                total = ones+zeros\n",
    "                #sum across the sequence for probabilities\n",
    "                logp=torch.sum(torch.log(total+1e-10),dim=2).squeeze(2)\n",
    "                logp+=torch.sum(torch.log(total0[:,:N]+1e-10),dim=1)\n",
    "                probs[:,N:(k+1)*L//D]=logp\n",
    "                \n",
    "        return sample,probs\n",
    "        \n",
    "    def sample(self,B,L):\n",
    "        \"\"\" Generates a set states\n",
    "        Inputs:\n",
    "            B (int)            - The number of states to generate in parallel\n",
    "            L (int)            - The length of generated vectors\n",
    "        Returns:\n",
    "            samples - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "        \"\"\"\n",
    "        #return (torch.rand([B,L,1],device=device)<0.5).to(torch.float32)\n",
    "        #Sample set will have shape [B,L,1]\n",
    "        #need one extra zero batch at the start for first pred hence input is [L+1,B,1] \n",
    "        #transformers don't do batch first so to save a bunch of transpose calls \n",
    "        input = torch.zeros([L+1,B,1],device=self.device)\n",
    "        #self.set_mask(L)\n",
    "        \n",
    "        cache=None\n",
    "        with torch.no_grad():\n",
    "          for idx in range(1,L+1):\n",
    "            #run the rnn on shape [B,1,1]   \n",
    "            #encode the input to the proper shape\n",
    "            encoded_input = self.pe(input[:idx,:,:])\n",
    "                        \n",
    "            #Get transformer output\n",
    "            output,cache = self.transformer.next_with_cache(encoded_input,cache)\n",
    "            #if probs[i]=1 then there should be a 100% chance that sample[i]=1\n",
    "            #if probs[i]=0 then there should be a 0% chance that sample[i]=1\n",
    "            #stands that we generate a random uniform u and take int(u<probs) as our sample\n",
    "            probs=self.lin(output[-1,:,:])\n",
    "            sample = (torch.rand([B,1],device=device)<probs).to(torch.float32)\n",
    "            input[idx,:,:]=sample\n",
    "        #input's first entry is zero to get a predction for the first atom\n",
    "        #print(\".\",end=\"\")\n",
    "        return input.transpose(1,0)[:,1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0855808",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PTFBase(Sampler):#(torch.jit.ScriptModule):\n",
    "    \"\"\"\n",
    "    Base class for the two patch transformer architectures \n",
    "    \n",
    "    Architexture wise this is how a patched transformer works:\n",
    "    \n",
    "    You give it a (2D) state and it patches it into groups of 4 (think of a 2x2 cnn filter with stride 2). It then tells you\n",
    "    the probability of each patch given it and all previous patches in your sequence using masked attention.\n",
    "    \n",
    "    Outputs should either be size 1 (the probability of the current patch which is input) or size 16 (for 2x2 patches where \n",
    "    the probability represented is of each potential patch)\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,Lx,_2D=False,device=device,Nh=128,dropout=0.0,num_layers=2,nhead=8,outsize=1, **kwargs):\n",
    "        super(PTFBase, self).__init__()\n",
    "        #print(nhead)\n",
    "        if _2D:\n",
    "            self.pe = PE2D(Nh, Lx//2,Lx//2,device)\n",
    "            self.patch=Patch2D(2,Lx)\n",
    "        else:\n",
    "            self.pe = PE1D(Nh,Lx//4,device)\n",
    "            self.patch=Patch1D(4,Lx)\n",
    "        self.device=device\n",
    "        #Encoder only transformer\n",
    "        #misinterperetation on encoder made it so this code does not work\n",
    "        self.transformer = FastMaskedTransformerEncoder(Nh=Nh,dropout=dropout,num_layers=num_layers,nhead=nhead)       \n",
    "        \n",
    "        self.lin = nn.Sequential(\n",
    "                nn.Linear(Nh,Nh),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(Nh,outsize),\n",
    "                nn.Sigmoid() if outsize==1 else nn.Softmax(dim=-1)\n",
    "            )\n",
    "        \n",
    "        self.Lx=Lx\n",
    "        if _2D:\n",
    "            self.set_mask(Lx**2//4)\n",
    "        else:\n",
    "            self.set_mask(Lx//4)\n",
    "        \n",
    "        self.options=torch.zeros([16,4],device=self.device)\n",
    "        tmp=torch.arange(16,device=self.device)\n",
    "        for i in range(4):\n",
    "            self.options[:,i]=(tmp>>i)%2\n",
    "        \n",
    "        \n",
    "        self.to(device)\n",
    "        \n",
    "    def set_mask(self, L):\n",
    "        # type: (int)\n",
    "        \"\"\"Initialize the self-attention mask\"\"\"\n",
    "        # take the log of a lower triangular matrix\n",
    "        self.L=L\n",
    "        self.transformer.set_mask(L)\n",
    "        self.pe.L=L\n",
    "        \n",
    "        \n",
    "    def forward(self, input):\n",
    "        # input is shape [B,L,1]\n",
    "        # add positional encoding to get shape [B,L,Nh]\n",
    "        if input.shape[1]//4!=self.L:\n",
    "            self.set_mask(input.shape[1]//4)\n",
    "        #pe should be sequence first [L,B,Nh]\n",
    "        input=self.pe(self.patch(input.squeeze(-1)).transpose(1,0))\n",
    "        output = self.transformer(input)\n",
    "        output = self.lin(output.transpose(1,0))\n",
    "        return output\n",
    "    \n",
    "# In[7]:\n",
    "\n",
    "\n",
    "class PTF(PTFBase):\n",
    "    \"\"\"Note: logprobability IS normalized \n",
    "    \n",
    "    Architexture wise this is how it works:\n",
    "    \n",
    "    You give it a (2D) state and it patches it into groups of 4 (think of a 2x2 cnn filter with stride 2). It then tells you\n",
    "    the probability of each potential patch given all previous patches in your sequence using masked attention.\n",
    "    \n",
    "    \n",
    "    This model has 16 outputs, which describes the probability distrubition for the nth patch when given the first n-1 patches\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,Lx,**kwargs):\n",
    "        #only important bit is that outsize = 16\n",
    "        super(PTF, self).__init__(Lx,outsize=16,**kwargs)\n",
    "    @torch.jit.export\n",
    "    def logprobability(self,input):\n",
    "        # type: (Tensor) -> Tensor\n",
    "        \"\"\"Compute the logscale probability of a given state\n",
    "            Inputs:\n",
    "                input - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "            Returns:\n",
    "                logp - [B] size vector of logscale probability labels\n",
    "        \"\"\"\n",
    "        \n",
    "        if input.shape[1]//4!=self.L:\n",
    "            self.set_mask(input.shape[1]//4)\n",
    "        #pe should be sequence first [L,B,Nh]\n",
    "        \n",
    "        #shape is modified to [L//4,B,4]\n",
    "        input = self.patch(input.squeeze(-1)).transpose(1,0)\n",
    "        \n",
    "        data=torch.zeros(input.shape,device=self.device)\n",
    "        data[1:]=input[:-1]\n",
    "        \n",
    "        #[L//4,B,4] -> [L//4,B,Nh]\n",
    "        encoded=self.pe(data)\n",
    "        #shape is preserved\n",
    "        output = self.transformer(encoded)\n",
    "        # [L//4,B,Nh] -> [L//4,B,16]\n",
    "        output = self.lin(output)\n",
    "        \n",
    "        #real is going to be a onehot with the index of the appropriate patch set to 1\n",
    "        #shape will be [L//4,B,16]\n",
    "        real=patch2onehot(input)\n",
    "        \n",
    "        #[L//4,B,16] -> [L//4,B]\n",
    "        total = torch.sum(real*output,dim=-1)\n",
    "        #[L//4,B] -> [B]\n",
    "        logp=torch.sum(torch.log(total+1e-10),dim=0)\n",
    "        return logp   \n",
    "    \n",
    "    @torch.jit.export\n",
    "    def sample(self,B,L,cache=None):\n",
    "        # type: (int,int,Optional[Tensor]) -> Tensor\n",
    "        \"\"\" Generates a set states\n",
    "        Inputs:\n",
    "            B (int)            - The number of states to generate in parallel\n",
    "            L (int)            - The length of generated vectors\n",
    "        Returns:\n",
    "            samples - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "        \"\"\"\n",
    "        #length is divided by four due to patching\n",
    "        L=L//4\n",
    "        \n",
    "        #return (torch.rand([B,L,1],device=device)<0.5).to(torch.float32)\n",
    "        #Sample set will have shape [B,L,1]\n",
    "        #need one extra zero batch at the start for first pred hence input is [L+1,B,1] \n",
    "        input = torch.zeros([L+1,B,4],device=self.device)\n",
    "         \n",
    "        with torch.no_grad():\n",
    "          for idx in range(1,L+1):\n",
    "            \n",
    "            #pe should be sequence first [L,B,Nh]\n",
    "            encoded_input = self.pe(input[:idx,:,:])\n",
    "                        \n",
    "            #Get transformer output\n",
    "            output,cache = self.transformer.next_with_cache(encoded_input,cache)\n",
    "            #check out the probability of all 16 vectors\n",
    "            probs=self.lin(output[-1,:,:]).view([B,16])\n",
    "\n",
    "            #sample from the probability distribution\n",
    "            indices = torch.multinomial(probs,1,False).squeeze(1)\n",
    "            #extract samples\n",
    "            sample = self.options[indices]\n",
    "            \n",
    "            #set input to the sample that was actually chosen\n",
    "            input[idx] = sample\n",
    "            \n",
    "        #remove the leading zero in the input    \n",
    "        input=input[1:]\n",
    "        #sample is repeated 16 times at 3rd index so we just take the first one\n",
    "        return self.patch.reverse(input.transpose(1,0)).unsqueeze(-1)\n",
    "    \n",
    "    \n",
    "    @torch.jit.export\n",
    "    def _off_diag_labels(self,sample,B,L,grad,D=1):\n",
    "        # type: (Tensor,int,int,bool,int) -> Tuple[Tensor, Tensor]\n",
    "        \"\"\"label all of the flipped states  - set D as high as possible without it slowing down runtime\n",
    "        Parameters:\n",
    "            sample - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "            B,L (int) - batch size and sequence length\n",
    "            D (int) - Number of partitions sequence-wise. We must have L%D==0 (D divides L)\n",
    "            \n",
    "        Outputs:\n",
    "            \n",
    "            sample - same as input\n",
    "            probs - [B,L] matrix of probabilities of states with the jth excitation flipped\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        sample0=sample\n",
    "        #sample is batch first at the moment\n",
    "        sample = self.patch(sample.squeeze(-1))\n",
    "        \n",
    "        sflip = torch.zeros([B,L,L//4,4],device=self.device)\n",
    "        #collect all of the flipped states into one array\n",
    "        for j in range(L//4):\n",
    "            #have to change the order of in which states are flipped for the cache to be useful\n",
    "            for j2 in range(4):\n",
    "                sflip[:,j*4+j2] = sample*1.0\n",
    "                sflip[:,j*4+j2,j,j2] = 1-sflip[:,j*4+j2,j,j2]\n",
    "            \n",
    "        #switch sample into sequence-first\n",
    "        sample = sample.transpose(1,0)\n",
    "            \n",
    "        #compute all of their logscale probabilities\n",
    "        with torch.no_grad():\n",
    "            \n",
    "\n",
    "            data=torch.zeros(sample.shape,device=self.device)\n",
    "            data[1:]=sample[:-1]\n",
    "            \n",
    "            #[L//4,B,4] -> [L//4,B,Nh]\n",
    "            encoded=self.pe(data)\n",
    "            \n",
    "            #add positional encoding and make the cache\n",
    "            out,cache=self.transformer.make_cache(encoded)\n",
    "            probs=torch.zeros([B,L],device=self.device)\n",
    "            #expand cache to group L//D flipped states\n",
    "            cache=cache.unsqueeze(2)\n",
    "\n",
    "            #this line took like 1 hour to write I'm so sad\n",
    "            #the cache has to be shaped such that the batch parts line up\n",
    "                        \n",
    "            cache=cache.repeat(1,1,L//D,1,1).transpose(2,3).reshape(cache.shape[0],L//4,B*L//D,cache.shape[-1])\n",
    "\n",
    "            pred0 = self.lin(out)\n",
    "            #shape will be [L//4,B,16]\n",
    "            real=patch2onehot(sample)\n",
    "            #[L//4,B,16] -> [B,L//4]\n",
    "            total0 = torch.sum(real*pred0,dim=-1).transpose(1,0)\n",
    "\n",
    "            for k in range(D):\n",
    "\n",
    "                N = k*L//D\n",
    "                #next couple of steps are crucial          \n",
    "                #get the samples from N to N+L//D\n",
    "                #Note: samples are the same as the original up to the Nth spin\n",
    "                real = sflip[:,N:(k+1)*L//D]\n",
    "                #flatten it out and set to sequence first\n",
    "                tmp = real.reshape([B*L//D,L//4,4]).transpose(1,0)\n",
    "                #set up next state predction\n",
    "                fsample=torch.zeros(tmp.shape,device=self.device)\n",
    "                fsample[1:]=tmp[:-1]\n",
    "                # put sequence before batch so you can use it with your transformer\n",
    "                tgt=self.pe(fsample)\n",
    "                #grab your transformer output\n",
    "                out,_=self.transformer.next_with_cache(tgt,cache[:,:N//4],N//4)\n",
    "\n",
    "                # grab output for the new part\n",
    "                output = self.lin(out[N//4:].transpose(1,0))\n",
    "                # reshape output separating batch from spin flip grouping\n",
    "                pred = output.view([B,L//D,(L-N)//4,16])\n",
    "                real = patch2onehot(real[:,:,N//4:])\n",
    "                total = torch.sum(real*pred,dim=-1)\n",
    "                #sum across the sequence for probabilities\n",
    "                \n",
    "                #print(total.shape,total0.shape)\n",
    "                logp=torch.sum(torch.log(total+1e-10),dim=-1)\n",
    "                logp+=torch.sum(torch.log(total0[:,:N//4]+1e-10),dim=-1).unsqueeze(-1)\n",
    "                probs[:,N:(k+1)*L//D]=logp\n",
    "                \n",
    "        return sample0,probs\n",
    "    @torch.jit.export\n",
    "    def sample_with_labelsALT(self,B,L,grad=False,nloops=1):\n",
    "        # type: (int,int,bool,int) -> Tuple[Tensor,Tensor,Tensor]\n",
    "        sample,probs = self.sample_with_labels(B,L,grad,nloops)\n",
    "        logsqrtp=probs.mean(dim=1)/2\n",
    "        sumsqrtp = torch.exp(probs/2-logsqrtp.unsqueeze(1)).sum(dim=1)\n",
    "        return sample,sumsqrtp,logsqrtp\n",
    "    @torch.jit.export\n",
    "    def sample_with_labels(self,B,L,grad=False,nloops=1):\n",
    "        # type: (int,int,bool,int) -> Tuple[Tensor,Tensor]\n",
    "        sample=self.sample(B,L,None)\n",
    "        return self._off_diag_labels(sample,B,L,grad,nloops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9ed665",
   "metadata": {},
   "outputs": [],
   "source": [
    "op=Opt()\n",
    "Lx=40\n",
    "op.L=Lx\n",
    "op.Nh=128\n",
    "op.lr=5e-4\n",
    "op.Q=1\n",
    "op.K=1024\n",
    "op.USEQUEUE=0\n",
    "#op.apply(sys.argv[1:])\n",
    "op.B=op.K*op.Q\n",
    "op.hamiltonian=\"TFIM\"\n",
    "#op.steps=4000\n",
    "op.dir=\"PTF\"\n",
    "op.steps=12000\n",
    "op.NLOOPS=10\n",
    "\n",
    "op.h=-1.0\n",
    "op.J=1.0\n",
    "print(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817c5a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "myptf=PTF(Lx,Nh=op.Nh,num_layers=2,_2D=False)\n",
    "\n",
    "trainsformer = torch.jit.script(myptf)\n",
    "#trainsformer = torch.jit.script(PatchedRNN(Lx,Nh=op.Nh))\n",
    "#trainsformer = RNN(Nh=op.Nh)\n",
    "#sampleformer= PatchedRNN(Lx,Nh=op.Nh)\n",
    "\n",
    "beta1=0.9;beta2=0.999\n",
    "optimizer = torch.optim.Adam(\n",
    "trainsformer.parameters(), \n",
    "lr=op.lr, \n",
    "betas=(beta1,beta2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5585ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if op.USEQUEUE:\n",
    "    queue_train(op,(trainsformer,sampleformer,optimizer))\n",
    "else:\n",
    "    print(\"Training. . .\")\n",
    "    reg_train(op,(trainsformer,optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1804631",
   "metadata": {},
   "outputs": [],
   "source": [
    "op=Opt()\n",
    "Lx=500\n",
    "op.L=Lx\n",
    "op.Nh=128\n",
    "op.lr=5e-4\n",
    "op.Q=1\n",
    "op.K=512\n",
    "op.USEQUEUE=0\n",
    "#op.apply(sys.argv[1:])\n",
    "op.B=op.K*op.Q\n",
    "op.hamiltonian=\"TFIM\"\n",
    "#op.steps=4000\n",
    "op.dir=\"PTF\"\n",
    "op.steps=12000\n",
    "op.NLOOPS=125\n",
    "\n",
    "op.h=-1.0\n",
    "op.J=1.0\n",
    "print(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ceeeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "myptf=PTF(Lx,Nh=op.Nh,num_layers=2,_2D=False)\n",
    "\n",
    "trainsformer = torch.jit.script(myptf)\n",
    "#trainsformer = torch.jit.script(PatchedRNN(Lx,Nh=op.Nh))\n",
    "#trainsformer = RNN(Nh=op.Nh)\n",
    "#sampleformer= PatchedRNN(Lx,Nh=op.Nh)\n",
    "\n",
    "beta1=0.9;beta2=0.999\n",
    "optimizer = torch.optim.Adam(\n",
    "trainsformer.parameters(), \n",
    "lr=op.lr, \n",
    "betas=(beta1,beta2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd3db35",
   "metadata": {},
   "outputs": [],
   "source": [
    "if op.USEQUEUE:\n",
    "    queue_train(op,(trainsformer,sampleformer,optimizer))\n",
    "else:\n",
    "    print(\"Training. . .\")\n",
    "    reg_train(op,(trainsformer,optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bd4027",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testRNN(RNN):\n",
    "    \"\"\"Just adds some functions which make sure all probability labels are consistent\"\"\"\n",
    "    def __init__(self,L,**kwargs):\n",
    "        super(testRNN,self).__init__(**kwargs)\n",
    "        self.L=L\n",
    "        self.reset(1)\n",
    "#functions below aren't really necessary anymore since there was no issue with masking (they serve to avoid using a mask)\n",
    "    def reset(self,B):\n",
    "        # type: (int) -> Tensor\n",
    "        \"\"\"Setup for an autoregressive transformer\"\"\"\n",
    "        self._input = torch.zeros([B,self.L+1,1],device=self.device)\n",
    "        self._i=1\n",
    "        h0=torch.zeros([1,B,self.Nh],device=self.device)\n",
    "        out,self._cache=self.rnn(torch.zeros([B,1,1],device=self.device),h0)\n",
    "        out=out[:,0,:]\n",
    "        probs=self.lin(out)\n",
    "        return probs\n",
    "    def forward(self,x):\n",
    "        return x\n",
    "    def getnext(self,vect):\n",
    "        # type: (Tensor) -> Tensor\n",
    "        \"\"\"Get probability for the next output in an autoregressive transformer\"\"\"\n",
    "        self._input[:,self._i]=vect\n",
    "        self._i+=1\n",
    "        out,self._cache=self.rnn(vect.unsqueeze(1),self._cache)\n",
    "        out=out[:,0,:]\n",
    "        probs=self.lin(out)\n",
    "        return probs\n",
    "    @torch.jit.export\n",
    "    def testsample(self,B):\n",
    "        # type: (int) -> Tuple[Tensor,Tensor]\n",
    "        \"\"\"Generate states with their probabilities in logscale\"\"\"\n",
    "        #set up variables\n",
    "        \n",
    "        L=self.L\n",
    "        probs=self.reset(B).squeeze(0)\n",
    "        sprobs=torch.zeros([B],device=self.device)\n",
    "        samples = torch.zeros([B,L,1],device=self.device)\n",
    "        #with torch.no_grad():\n",
    "        for idx in range(L):\n",
    "            #loop through L sequence elements and generate next in sequence based off of probabilities\n",
    "            sample = (torch.rand([B,1],device=self.device)<probs).to(torch.float32)\n",
    "            #print(sample.shape,samples.shape)\n",
    "            samples[:,idx] = sample\n",
    "            \n",
    "            ones = sample*probs\n",
    "            zeros=(1-sample)*(1-probs)\n",
    "            total = ones+zeros\n",
    "            sprobs+=torch.log(total).squeeze(-1)\n",
    "            if idx!=L-1: probs = self.getnext(sample)\n",
    "                \n",
    "        return samples,sprobs\n",
    "    \n",
    "    @torch.jit.export\n",
    "    def testlabels(self,samples,B):\n",
    "        # type: (Tensor,int) -> Tuple[Tensor,Tensor]\n",
    "        \"\"\"Get logscale probabilities of all states with one spin flipped at position j\"\"\"\n",
    "        L=self.L\n",
    "        with torch.no_grad():\n",
    "            #print(\"|\",end=\"\")\n",
    "            orig=samples\n",
    "            samples=samples*1\n",
    "            \n",
    "            logprobs=torch.zeros([B,L],device=self.device)\n",
    "            for k in range(L):\n",
    "                #loop cross L flipped states (batched)\n",
    "                probs=self.reset(B).squeeze(0)\n",
    "                sprobs = torch.zeros([B],device=self.device)\n",
    "                #loop across sequence\n",
    "                for idx in range(L):\n",
    "                    \n",
    "                    sample = samples[:,idx] \n",
    "                    #kth state is flipped\n",
    "                    if idx==k:\n",
    "                        #multiply by 1 as a way to copy the tensor to new memory\n",
    "                        sample=sample*1.0\n",
    "                        #print(sample.shape)\n",
    "                        sample[:,0] = 1-sample[:,0]\n",
    "                    \n",
    "                    ones = sample*probs\n",
    "                    zeros=(1-sample)*(1-probs)\n",
    "                    total = ones+zeros\n",
    "                    sprobs+=torch.log(total).squeeze(-1)\n",
    "                    if idx!=L-1: probs = self.getnext(sample)\n",
    "                logprobs[:,k]=sprobs\n",
    "        return orig,logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee17ea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydir = \"..\\\\NN-QSR\\\\RNN\\\\Rydberg\\\\64-NoQ-B=512-K=512-Nh=256-kl=0.00\\\\0\"\n",
    "op=Opt()\n",
    "op.L=64\n",
    "op.Nh=256\n",
    "tst=torch.load(mydir+\"/T\")\n",
    "\n",
    "tesRNN = torch.jit.script(testRNN(64,Nh=op.Nh))\n",
    "momentum_update(0,tesRNN,tst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db2da87",
   "metadata": {},
   "outputs": [],
   "source": [
    "op.K=512\n",
    "op.Q=8\n",
    "op.B=op.K*op.Q\n",
    "\n",
    "\n",
    "\n",
    "# Hamiltonian parameters\n",
    "N = op.L   # Total number of atoms\n",
    "V = 7.0     # Strength of Van der Waals interaction\n",
    "Omega = 1.0 # Rabi frequency\n",
    "delta = 1.0 # Detuning \n",
    "\n",
    "if op.hamiltonian==\"Rydberg\":\n",
    "    Lx=Ly=int(op.L**0.5)\n",
    "    op.L=Lx*Ly\n",
    "    h = Rydberg(Lx,Ly,V,Omega,delta)\n",
    "else:\n",
    "    #hope for the best here since there aren't defaults\n",
    "    h = TFIM(op.L,op.h,op.J)\n",
    "\n",
    "\n",
    "E_queue = torch.zeros([op.B],device=device)\n",
    "def fill_queue(net):\n",
    "    for i in range(op.Q):\n",
    "        print(\"|\",end=\"\")\n",
    "        if True:\n",
    "            with torch.no_grad():\n",
    "                sample,lp = net.testsample(op.K)\n",
    "                _,probs= net.testlabels(sample,op.K)\n",
    "            \n",
    "                #print(sample.shape)\n",
    "                E_i=h.localenergy(sample,lp,probs)\n",
    "                E_queue[i*op.K:(i+1)*op.K]=E_i\n",
    "        else:\n",
    "            sample,sump,sqrtp = net.sample_with_labelsALT(op.K,op.L,grad=False,nloops=144)\n",
    "            with torch.no_grad():\n",
    "                lp=net.logprobability(sample)\n",
    "                E_i=h.localenergyALT(sample,lp,sump,sqrtp)\n",
    "                E_queue[i*op.K:(i+1)*op.K]=E_i\n",
    "        \n",
    "            \n",
    "t=time.time()\n",
    "fill_queue(tesRNN)\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5691e344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def errformat(m,s):\n",
    "    exp = -int(np.floor(np.log(s)/np.log(10)))\n",
    "    print( str(round(m,exp))+\" +/- \"+str(round(s,exp)))\n",
    "\n",
    "var,mean = torch.var_mean(E_queue/op.L)\n",
    "\n",
    "print(h.ground(),op.B)\n",
    "stdv=((var/op.B)**0.5).item()\n",
    "errformat(mean.item(),stdv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abee450",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample,lp = tesRNN.testsample(op.K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7eaf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "lp2=tesRNN.logprobability(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de90639",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff=(lp-lp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc2509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(diff.reshape(16,16).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e20a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(diff).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458c2d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diff[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e017d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_train2(op,to=None):\n",
    "  try:\n",
    "\n",
    "    mydir = setup_dir(op)\n",
    "    \n",
    "    if type(to)==type(None):\n",
    "        trainrnn,optimizer=new_rnn_with_optim(\"GRU\",op.Nh,lr=op.lr)\n",
    "    else:\n",
    "        trainrnn,optimizer=to\n",
    "    # Hamiltonian parameters\n",
    "    N = op.L   # Total number of atoms\n",
    "    V = 7.0     # Strength of Van der Waals interaction\n",
    "    Omega = 1.0 # Rabi frequency\n",
    "    delta = 1.0 # Detuning \n",
    "\n",
    "    if op.hamiltonian==\"Rydberg\":\n",
    "        Lx=Ly=int(op.L**0.5)\n",
    "        op.L=Lx*Ly\n",
    "        h = Rydberg(Lx,Ly,V,Omega,delta)\n",
    "    else:\n",
    "        #hope for the best here since there aren't defaults\n",
    "        h = TFIM(op.L,op.h,op.J)\n",
    "    exact_energy = h.ground()\n",
    "    print(exact_energy,op.L)\n",
    "\n",
    "    debug=[]\n",
    "    losses=[]\n",
    "    true_energies=[]\n",
    "\n",
    "    # In[17]:\n",
    "\n",
    "    i=0\n",
    "    t=time.time()\n",
    "    for x in range(op.steps):\n",
    "        \n",
    "        #gather samples\n",
    "        sample,lp = trainrnn.testsample(op.K)\n",
    "        \n",
    "        logp=lp\n",
    "        #obtain energy\n",
    "        with torch.no_grad():\n",
    "            _,probs= trainrnn.testlabels(sample,op.K)\n",
    "            E=h.localenergy(sample,lp,probs)\n",
    "            #energy mean and variance\n",
    "            Ev,Eo=torch.var_mean(E)\n",
    "\n",
    "        ERR  = Eo/(op.L)\n",
    "        \n",
    "        \n",
    "        if op.B==1:\n",
    "            loss = ((E-op.kl)*logp).mean()\n",
    "        else:\n",
    "            #loss = (E*logp - Eo*logp).mean()\n",
    "            loss = (E*logp - (Eo+op.kl)*logp).mean()\n",
    "\n",
    "        #Main loss curve to follow\n",
    "        losses.append(ERR.cpu().item())\n",
    "\n",
    "        #update weights\n",
    "        trainrnn.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # many repeat values but it keeps the same format as no queue\n",
    "        debug+=[[Ev.item()**0.5,Eo.item(),Ev.item()**0.5,Eo.item(),loss.item(),Eo.item(),0,time.time()-t]]\n",
    "\n",
    "        if x%500==0:\n",
    "            print(int(time.time()-t),end=\",%.3f|\"%(losses[-1]))\n",
    "            if x%4000==0:print()\n",
    "    print(time.time()-t,x+1)\n",
    "\n",
    "    # In[18]:\n",
    "\n",
    "    import os\n",
    "    DEBUG = np.array(debug)\n",
    "    \n",
    "\n",
    "    if op.dir!=\"<NONE>\":\n",
    "        np.save(mydir+\"/DEBUG\",DEBUG)\n",
    "        #print(DEBUG[-1][3]/Lx/Ly-exact_energy,DEBUG[-1][3]/Lx/Ly,DEBUG[-1][1]/Lx/Ly,exact_energy)\n",
    "        trainrnn.save(mydir+\"/T\")\n",
    "        #torch.save(samplernn,mydir+\"/S\")\n",
    "        \n",
    "  except KeyboardInterrupt:\n",
    "    if op.dir!=\"<NONE>\":\n",
    "        import os\n",
    "        DEBUG = np.array(debug)\n",
    "        np.save(mydir+\"/DEBUG\",DEBUG)\n",
    "        #print(DEBUG[-1][3]/Lx/Ly-exact_energy,DEBUG[-1][3]/Lx/Ly,DEBUG[-1][1]/Lx/Ly,exact_energy)\n",
    "        trainrnn.save(mydir+\"/T\")\n",
    "        #torch.save(samplernn,mydir+\"/S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bf4b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "op.hamiltonian=\"Rydberg\"\n",
    "#op.steps=4000\n",
    "op.L=64\n",
    "op.B=op.K=512\n",
    "op.dir=\"TESTRNN\"\n",
    "op.steps=12000\n",
    "op.NLOOPS=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9fbf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesRNN = torch.jit.script(testRNN(64,Nh=op.Nh))\n",
    "\n",
    "beta1=0.9;beta2=0.999\n",
    "optimizer = torch.optim.Adam(\n",
    "tesRNN.parameters(), \n",
    "lr=op.lr, \n",
    "betas=(beta1,beta2)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c844b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_train2(op,(tesRNN,optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b829709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def genpatch2onehot(patch,p):\n",
    "    # type: (Tensor,int) -> Tensor\n",
    "    #moving the last dimension to the front\n",
    "    patch=patch.unsqueeze(0).transpose(-1,0).squeeze(-1)\n",
    "    out=torch.zeros(patch.shape[1:],device=patch.device)\n",
    "    for i in range(p):\n",
    "        out+=patch[i]<<i\n",
    "    return nn.functional.one_hot(out.to(torch.int64), num_classes=1<<p)\n",
    "\n",
    "\n",
    "\n",
    "class PatchedRNN(Sampler):\n",
    "    TYPES={\"GRU\":nn.GRU,\"ELMAN\":nn.RNN,\"LSTM\":nn.LSTM}\n",
    "    def __init__(self,L,p,_2D=False,rnntype=\"GRU\",Nh=128,device=device, **kwargs):\n",
    "        super(PatchedRNN, self).__init__(device=device)\n",
    "        \n",
    "        if _2D:\n",
    "            self.patch=Patch2D(p,L)\n",
    "            self.L = int(L**2//p**2)\n",
    "            self.p=int(p**2)\n",
    "        else:\n",
    "            self.patch=Patch1D(p,L)\n",
    "            self.L = int(L//p)\n",
    "            self.p = int(p)\n",
    "        \n",
    "        assert rnntype!=\"LSTM\"\n",
    "        #rnn takes input shape [B,L,1]\n",
    "        self.rnn = RNN.TYPES[rnntype](input_size=self.p,hidden_size=Nh,batch_first=True)\n",
    "        \n",
    "        \n",
    "        self.lin = nn.Sequential(\n",
    "                nn.Linear(Nh,Nh),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(Nh,1<<self.p),\n",
    "                nn.Softmax(dim=-1)\n",
    "            )\n",
    "        self.Nh=Nh\n",
    "        self.rnntype=rnntype\n",
    "        \n",
    "        \n",
    "        self.options=torch.zeros([1<<self.p,self.p],device=self.device)\n",
    "        tmp=torch.arange(1<<self.p,device=self.device)\n",
    "        for i in range(self.p):\n",
    "            self.options[:,i]=(tmp>>i)%2\n",
    "            \n",
    "        \n",
    "        self.to(device)\n",
    "    def forward(self, input):\n",
    "        # h0 is shape [d*numlayers,B,H] but D=numlayers=1 so\n",
    "        # h0 has shape [1,B,H]\n",
    "        \n",
    "        #if self.rnntype==\"LSTM\":\n",
    "        #    h0=[torch.zeros([1,input.shape[0],self.Nh],device=self.device),\n",
    "        #       torch.zeros([1,input.shape[0],self.Nh],device=self.device)]\n",
    "            #h0 and c0\n",
    "        #else:\n",
    "        h0=torch.zeros([1,input.shape[0],self.Nh],device=self.device)\n",
    "        out,h=self.rnn(input,h0)\n",
    "        return self.lin(out)\n",
    "    \n",
    "    @torch.jit.export\n",
    "    def logprobability(self,input):\n",
    "        # type: (Tensor) -> Tensor\n",
    "        \"\"\"Compute the logscale probability of a given state\n",
    "            Inputs:\n",
    "                input - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "            Returns:\n",
    "                logp - [B] size vector of logscale probability labels\n",
    "        \"\"\"\n",
    "                \n",
    "        #shape is modified to [B,L//4,4]\n",
    "        input = self.patch(input.squeeze(-1))\n",
    "        data=torch.zeros(input.shape,device=self.device)\n",
    "        #batch first\n",
    "        data[:,1:]=input[:,:-1]\n",
    "        # [B,L//4,Nh] -> [B,L//4,16]\n",
    "        output = self.forward(data)\n",
    "        \n",
    "        #real is going to be a onehot with the index of the appropriate patch set to 1\n",
    "        #shape will be [B,L//4,16]\n",
    "        real=genpatch2onehot(input,self.p)\n",
    "        \n",
    "        #[B,L//4,16] -> [B,L//4]\n",
    "        total = torch.sum(real*output,dim=-1)\n",
    "        #[B,L//4] -> [B]\n",
    "        logp=torch.sum(torch.log(total),dim=1)\n",
    "        return logp\n",
    "    @torch.jit.export\n",
    "    def sample(self,B,L,cache=None):\n",
    "        # type: (int,int,Optional[Tensor]) -> Tensor\n",
    "        \"\"\" Generates a set states\n",
    "        Inputs:\n",
    "            B (int)            - The number of states to generate in parallel\n",
    "            L (int)            - The length of generated vectors\n",
    "        Returns:\n",
    "            samples - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "        \"\"\"\n",
    "        #length is divided by four due to patching\n",
    "        L=L//self.p\n",
    "        #if self.rnntype==\"LSTM\":\n",
    "        #    h=[torch.zeros([1,B,self.Nh],device=self.device),\n",
    "        #       torch.zeros([1,B,self.Nh],device=self.device)]\n",
    "            #h is h0 and c0\n",
    "        #else:\n",
    "        h=torch.zeros([1,B,self.Nh],device=self.device)\n",
    "        #Sample set will have shape [B,L,p]\n",
    "        #need one extra zero batch at the start for first pred hence input is [L+1,B,1] \n",
    "        input = torch.zeros([B,L+1,self.p],device=self.device)\n",
    "         \n",
    "        with torch.no_grad():\n",
    "          for idx in range(1,L+1):\n",
    "            #out should be batch first [B,L,Nh]\n",
    "            out,h=self.rnn(input[:,idx-1:idx,:],h)\n",
    "            #check out the probability of all 1<<p vectors\n",
    "            probs=self.lin(out[:,0,:]).view([B,1<<self.p])\n",
    "            #sample from the probability distribution\n",
    "            indices = torch.multinomial(probs,1,False).squeeze(1)\n",
    "            #extract samples\n",
    "            sample = self.options[indices]\n",
    "            #set input to the sample that was actually chosen\n",
    "            input[:,idx] = sample\n",
    "        #remove the leading zero in the input    \n",
    "        #sample is repeated 16 times at 3rd index so we just take the first one\n",
    "        return self.patch.reverse(input[:,1:]).unsqueeze(-1)\n",
    "    \n",
    "    @torch.jit.export\n",
    "    def sample_with_labelsALT(self,B,L,grad=False,nloops=1):\n",
    "        # type: (int,int,bool,int) -> Tuple[Tensor,Tensor,Tensor]\n",
    "        sample,probs = self.sample_with_labels(B,L,grad,nloops)\n",
    "        logsqrtp=probs.mean(dim=1)/2\n",
    "        sumsqrtp = torch.exp(probs/2-logsqrtp.unsqueeze(1)).sum(dim=1)\n",
    "        return sample,sumsqrtp,logsqrtp\n",
    "    @torch.jit.export\n",
    "    def sample_with_labels(self,B,L,grad=False,nloops=1):\n",
    "        # type: (int,int,bool,int) -> Tuple[Tensor,Tensor]\n",
    "        sample=self.sample(B,L,None)\n",
    "        return self._off_diag_labels(sample,B,L,grad,nloops)\n",
    "    \n",
    "    \n",
    "    @torch.jit.export\n",
    "    def _off_diag_labels(self,sample,B,L,grad,D=1):\n",
    "        # type: (Tensor,int,int,bool,int) -> Tuple[Tensor, Tensor]\n",
    "        \"\"\"label all of the flipped states  - set D as high as possible without it slowing down runtime\n",
    "        Parameters:\n",
    "            sample - [B,L,1] matrix of zeros and ones for ground/excited states\n",
    "            B,L (int) - batch size and sequence length\n",
    "            D (int) - Number of partitions sequence-wise. We must have L%D==0 (D divides L)\n",
    "            \n",
    "        Outputs:\n",
    "            \n",
    "            sample - same as input\n",
    "            probs - [B,L] matrix of probabilities of states with the jth excitation flipped\n",
    "        \"\"\"\n",
    "        sample0=sample\n",
    "        #sample is batch first at the moment\n",
    "        sample = self.patch(sample.squeeze(-1))\n",
    "        \n",
    "        sflip = torch.zeros([B,L,L//self.p,self.p],device=self.device)\n",
    "        #collect all of the flipped states into one array\n",
    "        for j in range(L//self.p):\n",
    "            #have to change the order of in which states are flipped for the cache to be useful\n",
    "            for j2 in range(self.p):\n",
    "                sflip[:,j*self.p+j2] = sample*1.0\n",
    "                sflip[:,j*self.p+j2,j,j2] = 1-sflip[:,j*self.p+j2,j,j2]\n",
    "            \n",
    "        #compute all of their logscale probabilities\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            data=torch.zeros(sample.shape,device=self.device)\n",
    "            \n",
    "            data[:,1:]=sample[:,:-1]\n",
    "            \n",
    "            #add positional encoding and make the cache\n",
    "            \n",
    "            h=torch.zeros([1,B,self.Nh],device=self.device)\n",
    "            \n",
    "            out,_=self.rnn(data,h)\n",
    "            \n",
    "            #cache for the rnn is the output in this sense\n",
    "            #shape [B,L//4,Nh]\n",
    "            cache=out\n",
    "            probs=torch.zeros([B,L],device=self.device)\n",
    "            #expand cache to group L//D flipped states\n",
    "            cache=cache.unsqueeze(1)\n",
    "\n",
    "            #this line took like 1 hour to write I'm so sad\n",
    "            #the cache has to be shaped such that the batch parts line up\n",
    "                        \n",
    "            cache=cache.repeat(1,L//D,1,1).reshape(B*L//D,L//self.p,cache.shape[-1])\n",
    "                        \n",
    "            pred0 = self.lin(out)\n",
    "            #shape will be [B,L//4,16]\n",
    "            real=genpatch2onehot(sample,self.p)\n",
    "            #[B,L//4,16] -> [B,L//4]\n",
    "            total0 = torch.sum(real*pred0,dim=-1)\n",
    "\n",
    "            for k in range(D):\n",
    "\n",
    "                N = k*L//D\n",
    "                #next couple of steps are crucial          \n",
    "                #get the samples from N to N+L//D\n",
    "                #Note: samples are the same as the original up to the Nth spin\n",
    "                real = sflip[:,N:(k+1)*L//D]\n",
    "                #flatten it out and set to sequence first\n",
    "                tmp = real.reshape([B*L//D,L//self.p,self.p])\n",
    "                #set up next state predction\n",
    "                fsample=torch.zeros(tmp.shape,device=self.device)\n",
    "                fsample[:,1:]=tmp[:,:-1]\n",
    "                #grab your rnn output\n",
    "                if k==0:\n",
    "                    out,_=self.rnn(fsample,cache[:,0].unsqueeze(0)*0.0)\n",
    "                else:\n",
    "                    out,_=self.rnn(fsample[:,N//self.p:],cache[:,N//self.p-1].unsqueeze(0)*1.0)\n",
    "                # grab output for the new part\n",
    "                output = self.lin(out)\n",
    "                # reshape output separating batch from spin flip grouping\n",
    "                pred = output.view([B,L//D,(L-N)//self.p,1<<self.p])\n",
    "                real = genpatch2onehot(real[:,:,N//self.p:],self.p)\n",
    "                total = torch.sum(real*pred,dim=-1)\n",
    "                #sum across the sequence for probabilities\n",
    "                #print(total.shape,total0.shape)\n",
    "                logp=torch.sum(torch.log(total),dim=-1)\n",
    "                logp+=torch.sum(torch.log(total0[:,:N//self.p]),dim=-1).unsqueeze(-1)\n",
    "                probs[:,N:(k+1)*L//D]=logp\n",
    "                \n",
    "        return sample0,probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965263ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dd35feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "op=Opt()\n",
    "op.hamiltonian=\"Rydberg\"\n",
    "#op.steps=4000\n",
    "op.L=64\n",
    "op.B=op.K=512\n",
    "op.Q=1\n",
    "op.Nh=256\n",
    "op.dir=\"TESTRNN\"\n",
    "op.USEQUEUE=0\n",
    "op.steps=12000\n",
    "op.NLOOPS=16\n",
    "op.patch=1\n",
    "op.lr=5e-4\n",
    "op._2D=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05e372d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesRNN = torch.jit.script(PatchedRNN(64,op.patch,Nh=op.Nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f301cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta1=0.9;beta2=0.999\n",
    "optimizer = torch.optim.Adam(\n",
    "tesRNN.parameters(), \n",
    "lr=op.lr, \n",
    "betas=(beta1,beta2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4fca488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output folder path established\n",
      "-0.40522 64\n",
      "0,2.667|\n",
      "53,-0.318|107,-0.370|160,-0.388|214,-0.387|268,-0.391|321,-0.393|375,-0.394|429,-0.395|\n",
      "482,-0.398|536,-0.399|590,-0.400|644,-0.403|697,-0.404|751,-0.405|805,-0.405|859,-0.405|\n",
      "913,-0.405|967,-0.405|1020,-0.405|1074,-0.405|1128,-0.405|1182,-0.405|1235,-0.405|1289.6270954608917 12000\n"
     ]
    }
   ],
   "source": [
    "reg_train(op,(tesRNN,optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23a533d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesRNN = torch.jit.script(PRNN(64,4,Nh=256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42da575b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 64, 1]) torch.Size([4]) tensor([-44.2473, -44.3562, -44.1316, -44.3067], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sample,logp=tesRNN.sample(4,64)\n",
    "\n",
    "print(sample.shape,logp.shape,logp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "926e2920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesRNN.off_diag_labels(sample,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0837575",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = PRNN(64,4,Nh=256)\n",
    "s,p0 = t2.sample(4,64)\n",
    "p1 = t2.logprobability(s)\n",
    "\n",
    "dp0 = super(PRNN,t2).off_diag_labels(s,1)\n",
    "dp2 = super(PRNN,t2).off_diag_labels(s,4)\n",
    "dp1 = t2.off_diag_labels(s,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a8c0e9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0.029595360159873962\n",
      "1.6704201698303223e-05 -1.6540288925170898e-06 2.002716064453125e-05 0.023155638948082924\n"
     ]
    }
   ],
   "source": [
    "print(abs(p0-p1).mean().item(),(p0-p1).mean().item(),p0.var().item())\n",
    "\n",
    "print(abs(dp0-dp1).mean().item(),(dp0-dp1).mean().item(),abs(dp0-dp2).mean().item(),dp0.var().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f159c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.273566852856423"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIM(L=40,h_x=-1).ground()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce68c1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"python RNN_QSR.py hamiltonian=TFIM L=40 NLOOPS=10 h=-1 J=1 patch=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ae730de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"python RNN_QSR.py hamiltonian=TFIM L=100 NLOOPS=25 h=-1 J=1 patch=1\")\n",
    "os.system(\"python RNN_QSR.py hamiltonian=TFIM L=100 NLOOPS=25 h=-1 J=1 patch=4\")\n",
    "os.system(\"python RNN_QSR.py hamiltonian=TFIM L=200 NLOOPS=50 h=-1 J=1 patch=4\")\n",
    "os.system(\"python RNN_QSR.py hamiltonian=TFIM L=500 NLOOPS=125 h=-1 J=1 patch=4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86e12de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"python PTF.py hamiltonian=TFIM L=40 NLOOPS=10 h=-1 J=1 patch=4 K=512\")\n",
    "os.system(\"python PTF.py hamiltonian=TFIM L=100 NLOOPS=25 h=-1 J=1 patch=4 K=512\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8a19584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"python PTF.py hamiltonian=TFIM L=200 NLOOPS=50 h=-1 J=1 patch=4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15844bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"python PTF.py hamiltonian=TFIM L=500 NLOOPS=125 h=-1 J=1 patch=4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91b0ab71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"python PTF.py hamiltonian=Rydberg L=576 NLOOPS=144 patch=4 _2D=True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60934841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
